"""
é¢˜å·ç­”æ¡ˆç”Ÿæˆå™¨
è§£æ Word é¢˜å·ï¼Œè°ƒç”¨ LLM ç”Ÿæˆ5ä¸ªä¸åŒç­‰çº§çš„å­¦ç”Ÿç­”æ¡ˆï¼Œå¹¶ç”Ÿæˆ .docx æ–‡ä»¶
"""

import json
import os
import re
import asyncio
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime

try:
    from docx import Document
    from docx.shared import Pt, RGBColor
    from docx.enum.text import WD_PARAGRAPH_ALIGNMENT, WD_BREAK
except ImportError:
    Document = None

import requests

# Import Cloud API functions
from homework_reviewer_v2 import upload_file, homework_file_analysis


def load_llm_config_from_args(context: dict) -> Tuple[str, str, str]:
    """ä»ä¸Šä¸‹æ–‡åŠ è½½ LLM é…ç½®"""
    api_key = context.get("llm_api_key") or os.getenv("LLM_API_KEY", "")
    api_url = context.get("llm_api_url") or os.getenv("LLM_API_URL", "http://llm-service.polymas.com/api/openai/v1/chat/completions")
    model = context.get("llm_model") or os.getenv("LLM_MODEL", "gpt-4o")
    return api_key, api_url, model


def extract_questions_from_cloud(docx_path: Path, context: dict) -> Tuple[str, str]:
    """
    ä½¿ç”¨äº‘ç«¯ API è§£æé¢˜å·ç»“æ„ï¼š
    1. upload_file  â†’ è·å– fileUrl
    2. homework_file_analysis â†’ è·å– textInput ç»“æ„
    """
    authorization = os.getenv("AUTHORIZATION", "")
    cookie_env = os.getenv("COOKIE", "")
    if not authorization or not cookie_env:
        print(f"ğŸ“„ ä½¿ç”¨æœ¬åœ°è§£ææ¨¡å¼")
        return extract_questions_from_local(docx_path)

    auth_preview = authorization[:20] + "..." if len(authorization) > 20 else authorization
    print(f"â˜ï¸ æ­£åœ¨ä¸Šä¼ é¢˜å·åˆ°äº‘ç«¯: {docx_path.name} (auth={auth_preview})")
    try:
        # Step 1: ä¸Šä¼ æ–‡ä»¶è·å– fileUrl
        file_info = upload_file(str(docx_path))
        if not file_info or not file_info.get("fileUrl"):
            raise ValueError("æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œæœªè·å–åˆ° fileUrlã€‚è¯·æ£€æŸ¥ Authorization/Cookie æ˜¯å¦å·²è¿‡æœŸ")

        print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file_info.get('fileName')}")

        # Step 2: è°ƒç”¨ homework_file_analysis è§£æé¢˜å·ç»“æ„
        print(f"â˜ï¸ æ­£åœ¨è§£æé¢˜å·ç»“æ„...")
        success, result, text_input = homework_file_analysis(file_info, context)

        if not success or not text_input:
            error_msg = ""
            if isinstance(result, dict):
                error_msg = result.get("error", "") or result.get("msg", "")
            raise ValueError(f"äº‘ç«¯è§£æå¤±è´¥: {error_msg}")

        print(f"âœ… é¢˜å·ç»“æ„è§£æå®Œæˆ")

        # text_input æ˜¯ JSON å­—ç¬¦ä¸²ï¼Œè§£æä¸ºç»“æ„åŒ–å†…å®¹ç»™ LLM
        title = docx_path.stem  # é»˜è®¤æ ‡é¢˜ç”¨æ–‡ä»¶å

        parsed = text_input
        if isinstance(text_input, str):
            try:
                parsed = json.loads(text_input)
            except json.JSONDecodeError:
                # çº¯æ–‡æœ¬ç›´æ¥ç”¨
                return title, text_input

        # å¦‚æœæ˜¯åˆ—è¡¨ç»“æ„ [{ itemName, stuAnswerContent }, ...]
        # æ ¼å¼åŒ–ä¸ºå¯è¯»æ–‡æœ¬
        if isinstance(parsed, list):
            full_text_lines = []
            for i, item in enumerate(parsed):
                item_name = item.get("itemName", "")
                content = item.get("stuAnswerContent", "")
                if item_name or content:
                    full_text_lines.append(f"ã€{item_name}ã€‘" if item_name else f"é¢˜ç›®{i + 1}:")
                    if content:
                        full_text_lines.append(content)
                    full_text_lines.append("")
            return title, "\n".join(full_text_lines)

        if isinstance(parsed, dict):
            return title, json.dumps(parsed, ensure_ascii=False, indent=2)

        return title, str(parsed)

    except Exception as e:
        print(f"âš ï¸ äº‘ç«¯è§£æå¤±è´¥ ({e})ï¼Œå°è¯•æœ¬åœ°è§£æ...")
        return extract_questions_from_local(docx_path)


def extract_questions_from_local(docx_path: Path) -> Tuple[str, str]:
    """
    æœ¬åœ°è§£æä½œä¸ºå…œåº•
    """
    if Document is None:
        raise ImportError("è¯·å®‰è£… python-docx: pip install python-docx")
    
    doc = Document(docx_path)
    
    title = ""
    for p in doc.paragraphs[:5]:
        if p.text.strip():
            title = p.text.strip()
            break
            
    full_text = []
    for p in doc.paragraphs:
        if p.text.strip():
            full_text.append(p.text.strip())
            
    return title, "\n".join(full_text)


def build_generation_prompt(title: str, exam_content: str, level: str, level_desc: str) -> str:
    """æ„å»ºç”Ÿæˆç­”æ¡ˆçš„ Prompt"""
    return f"""ä½ æ˜¯ä¸€åã€{level}ã€‘æ°´å¹³çš„å­¦ç”Ÿï¼Œæ­£åœ¨ä½œç­”ã€Š{title}ã€‹ã€‚
è¯·æ ¹æ®ä½ çš„æ°´å¹³è¦æ±‚å®Œæˆæ‰€æœ‰é¢˜ç›®ã€‚

ã€ç­‰çº§è¦æ±‚ï¼š{level}ã€‘
{level_desc}

ã€è¯•å·å†…å®¹ã€‘
{exam_content[:15000]}  # é™åˆ¶é•¿åº¦é˜²æ­¢è¶…é™

ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºä½ çš„ç­”æ¡ˆï¼Œä¸è¦åŒ…å«ä»»ä½•å¤šä½™çš„å¼€åœºç™½æˆ–è§£é‡Šï¼š

ä¸€ã€å•é¡¹é€‰æ‹©é¢˜ï¼ˆæ¯é¢˜2åˆ†ï¼Œå…±20åˆ†ï¼‰
1.A 2.B 3.C ...

äºŒã€åˆ¤æ–­é¢˜ï¼ˆæ¯é¢˜2åˆ†ï¼Œå…±20åˆ†ï¼‰
1.âˆš 2.Ã— 3.âˆš ...

ä¸‰ã€ç®€ç­”é¢˜ï¼ˆæ¯é¢˜5åˆ†ï¼Œå…±20åˆ†ï¼‰
1. ç®€è¿°...ï¼ˆé¢˜ç›®ï¼‰
ï¼ˆä½ çš„ç­”æ¡ˆå†…å®¹...ï¼‰

å››ã€è®ºè¿°é¢˜ï¼ˆæ¯é¢˜10åˆ†ï¼Œå…±20åˆ†ï¼‰
1. è®ºè¿°...ï¼ˆé¢˜ç›®ï¼‰
ï¼ˆä½ çš„ç­”æ¡ˆå†…å®¹...ï¼‰

...ï¼ˆå…¶ä»–é¢˜å‹ä¾æ¬¡ç±»æ¨ï¼‰

æ³¨æ„ï¼š
1. å¿…é¡»åŒ…å«é¢˜å‹æ ‡é¢˜ï¼ˆå¦‚"ä¸€ã€å•é¡¹é€‰æ‹©é¢˜"ï¼‰
2. é€‰æ‹©é¢˜å’Œåˆ¤æ–­é¢˜è¯·å°½é‡ç´§å‡‘ï¼Œæ¯è¡Œå¤šä¸ª
3. ä¸»è§‚é¢˜è¯·å†™å‡ºå®Œæ•´çš„ç­”æ¡ˆå†…å®¹ï¼Œä¸è¦åªå†™è¦ç‚¹
4. ç­”æ¡ˆçš„è´¨é‡å¿…é¡»ç¬¦åˆã€{level}ã€‘çš„è®¾å®šï¼Œå¦‚æœæ˜¯è¾ƒå·®ç­‰çº§ï¼Œå¯ä»¥æ•…æ„åŒ…å«ä¸€äº›é”™è¯¯æˆ–é€»è¾‘ä¸æ¸…çš„å†…å®¹ã€‚
"""


async def generate_answer_content(prompt: str, context: dict) -> Optional[str]:
    """è°ƒç”¨ LLM ç”Ÿæˆç­”æ¡ˆå†…å®¹"""
    api_key, api_url, model = load_llm_config_from_args(context)
    
    if not api_key:
        print("âŒ æœªé…ç½® LLM API Keyï¼Œè¯·åœ¨å³ä¸Šè§’ âš™ï¸ è®¾ç½®ä¸­é…ç½®")
        print(f"   context keys: {list(context.keys())}")
        print(f"   env LLM_API_KEY set: {bool(os.getenv('LLM_API_KEY'))}")
        return None
    
    # é¦–æ¬¡è°ƒç”¨æ—¶æ‰“å°é…ç½®ï¼ˆè„±æ•ï¼‰
    key_preview = api_key[:8] + "..." + api_key[-4:] if len(api_key) > 12 else "***"
    print(f"ğŸ”§ LLM é…ç½®: url={api_url}, model={model}, key={key_preview}")
        
    headers = {
        "api-key": api_key,
        "Content-Type": "application/json"
    }
    
    payload = {
        "maxTokens": 4096,
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªæ¨¡æ‹ŸçœŸå®å­¦ç”Ÿä½œç­”çš„AIåŠ©æ‰‹ã€‚ä½ ä¼šæ ¹æ®æŒ‡å®šçš„èƒ½åŠ›ç­‰çº§ï¼Œç”Ÿæˆç¬¦åˆè¯¥æ°´å¹³çš„è¯•å·ç­”æ¡ˆã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "model": model, 
        "temperature": 0.5,
    }
    
    try:
        # ä½¿ç”¨ run_in_executor è¿›è¡Œå¼‚æ­¥è°ƒç”¨
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None, 
            lambda: requests.post(api_url, headers=headers, json=payload, timeout=180)
        )
        
        if response.status_code != 200:
            body_preview = response.text[:500] if response.text else "(empty)"
            print(f"âŒ LLM API è¿”å› {response.status_code}: {body_preview}")
            print(f"   è¯·æ±‚ URL: {api_url}")
            print(f"   è¯·æ±‚ Model: {model}")
            print(f"   API Key å‰ç¼€: {api_key[:10]}..." if len(api_key) > 10 else f"   API Key: (len={len(api_key)})")
            response.raise_for_status()
        
        result = response.json()
        
        if "choices" in result and len(result["choices"]) > 0:
            return result["choices"][0]["message"]["content"]
        print(f"âš ï¸ LLM å“åº”ä¸­æ²¡æœ‰ choices: {json.dumps(result, ensure_ascii=False)[:300]}")
        return None
    except requests.exceptions.HTTPError:
        # å·²åœ¨ä¸Šé¢æ‰“å°è¯¦ç»†ä¿¡æ¯
        return None
    except Exception as e:
        print(f"âŒ LLM ç”Ÿæˆå¤±è´¥: {type(e).__name__}: {e}")
        return None


def create_answer_docx(content: str, output_path: Path, title: str, level: str, level_desc: str):
    """å°†ç”Ÿæˆçš„æ–‡æœ¬å†™å…¥ Word æ–‡æ¡£ï¼Œæ¨¡ä»¿æ ‡å‡†æ ¼å¼"""
    doc = Document()
    
    # 1. è¯•å·æ ‡é¢˜
    p_title = doc.add_paragraph(f"{title}äº”ç­‰çº§å­¦ç”Ÿç­”æ¡ˆ")
    if p_title.runs: p_title.runs[0].bold = True
    
    # 2. ç­‰çº§æè¿°
    p_level = doc.add_paragraph(f"ç­‰çº§ï¼š{level}ï¼ˆ{level_desc}ï¼‰")
    if p_level.runs: p_level.runs[0].bold = True 
    
    # 3. å†™å…¥å†…å®¹
    # ç®€å•å¤„ç†ï¼šæŒ‰è¡Œå†™å…¥ï¼Œè¯†åˆ«åˆ°é¢˜å‹æ ‡é¢˜åŠ ç²—
    lines = content.split('\n')
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        p = doc.add_paragraph(line)
        
        # è¯†åˆ«é¢˜å‹æ ‡é¢˜åŠ ç²— (ä¸€ã€xxx)
        if re.match(r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€\.]', line):
            if p.runs: p.runs[0].bold = True
            
    doc.save(output_path)


LEVEL_DEFINITIONS = {
    "ä¼˜ç§€çš„å›ç­”": "æ»¡åˆ†90-100åˆ†ï¼ŒçŸ¥è¯†å…¨é¢ç²¾å‡†ï¼Œé€»è¾‘æ¸…æ™°è¿è´¯ï¼Œæ¡ˆä¾‹ç»“åˆåˆ°ä½ï¼Œåˆè§„ç»†èŠ‚æ— é—æ¼",
    "è‰¯å¥½çš„å›ç­”": "æ»¡åˆ†80-89åˆ†ï¼ŒçŸ¥è¯†ç‚¹è¦†ç›–è¾ƒå…¨ï¼Œé€»è¾‘è¾ƒæ¸…æ™°ï¼Œæœ‰ä¸€å®šæ¡ˆä¾‹ç»“åˆï¼Œå¶æœ‰å°ç‘•ç–µ",
    "ä¸­ç­‰çš„å›ç­”": "æ»¡åˆ†70-79åˆ†ï¼ŒåŸºæœ¬çŸ¥è¯†ç‚¹æŒæ¡ï¼Œé€»è¾‘ä¸€èˆ¬ï¼Œæ¡ˆä¾‹ç»“åˆè¾ƒå°‘ï¼Œè¡¨è¿°å¹³é“ºç›´å™",
    "åˆæ ¼çš„å›ç­”": "æ»¡åˆ†60-69åˆ†ï¼Œæ ¸å¿ƒçŸ¥è¯†ç‚¹æœ‰é—æ¼ï¼Œé€»è¾‘ä¸å¤Ÿä¸¥å¯†ï¼Œè¡¨è¿°å­˜åœ¨æ¨¡ç³Šä¹‹å¤„",
    "è¾ƒå·®çš„å›ç­”": "æ»¡åˆ†60åˆ†ä»¥ä¸‹ï¼ŒçŸ¥è¯†æ¼æ´å¤šï¼Œé€»è¾‘æ··ä¹±ï¼Œæœªç»“åˆæ¡ˆä¾‹ï¼Œå­˜åœ¨æ˜æ˜¾é”™è¯¯"
}

LEVEL_FILENAMES = {
    "ä¼˜ç§€çš„å›ç­”": "ç­‰çº§ä¸€_ä¼˜ç§€_å­¦ç”Ÿç­”æ¡ˆ",
    "è‰¯å¥½çš„å›ç­”": "ç­‰çº§äºŒ_è‰¯å¥½_å­¦ç”Ÿç­”æ¡ˆ",
    "ä¸­ç­‰çš„å›ç­”": "ç­‰çº§ä¸‰_ä¸­ç­‰_å­¦ç”Ÿç­”æ¡ˆ",
    "åˆæ ¼çš„å›ç­”": "ç­‰çº§å››_åˆæ ¼_å­¦ç”Ÿç­”æ¡ˆ",
    "è¾ƒå·®çš„å›ç­”": "ç­‰çº§äº”_è¾ƒå·®_å­¦ç”Ÿç­”æ¡ˆ"
}


async def generate_level_answers(
    exam_docx_path: Path,
    output_dir: Path,
    levels: List[str],  # e.g., ["ä¼˜ç§€çš„å›ç­”", "è¾ƒå·®çš„å›ç­”"]
    context: dict
) -> List[Path]:
    """
    ç”ŸæˆæŒ‡å®šç­‰çº§çš„ç­”æ¡ˆæ–‡ä»¶
    """
    print(f"ğŸ“„ æ­£åœ¨è§£æé¢˜å·: {exam_docx_path.name}")
    try:
        title, exam_content = extract_questions_from_cloud(exam_docx_path, context)
    except Exception as e:
        print(f"âŒ è§£æé¢˜å·å¤±è´¥: {e}")
        return []

    print(f"âœ… é¢˜å·è§£æå®Œæˆï¼Œæ ‡é¢˜: {title}ï¼Œç›®æ ‡ç”Ÿæˆ {len(levels)} ä»½ç­”æ¡ˆ")
    
    output_dir.mkdir(parents=True, exist_ok=True)
    generated_files = []
    
    # å¹¶å‘ç”Ÿæˆ
    tasks = []
    for level_key in levels:
        # æ˜ å°„ level key åˆ°æè¿°
        # å‰ç«¯ä¼ æ¥çš„å¯èƒ½æ˜¯ "ä¼˜ç§€", "è‰¯å¥½" ç­‰ç®€å†™ï¼Œéœ€è¦åŒ¹é…
        full_key = next((k for k in LEVEL_DEFINITIONS if level_key in k), level_key)
        
        desc = LEVEL_DEFINITIONS.get(full_key, "æ— æè¿°")
        file_suffix = LEVEL_FILENAMES.get(full_key, f"{level_key}_å­¦ç”Ÿç­”æ¡ˆ")
        
        clean_title = re.sub(r'[\\/:*?"<>|]', '_', title)
        filename = f"{clean_title}_{file_suffix}.docx"
        output_path = output_dir / filename
        
        tasks.append((full_key, desc, output_path))

    # æ‰§è¡Œç”Ÿæˆä»»åŠ¡
    for level, desc, path in tasks:
        print(f"ğŸ¤– æ­£åœ¨ç”Ÿæˆ: {level}...")
        prompt = build_generation_prompt(title, exam_content, level, desc)
        content = await generate_answer_content(prompt, context)
        
        if content:
            create_answer_docx(content, path, title, level, desc)
            print(f"âœ… ç”Ÿæˆå®Œæ¯•: {path.name}")
            generated_files.append(path)
        else:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {level}")

    return generated_files
