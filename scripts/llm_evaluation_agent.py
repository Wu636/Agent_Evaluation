#!/usr/bin/env python3
"""
åŸºäºLLMçš„å®è®­æ™ºèƒ½ä½“è¯„æµ‹ç³»ç»Ÿ
ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ·±åº¦è¯­ä¹‰ç†è§£å’Œè¯„æµ‹
"""

import json
import os
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from enum import Enum


class EvaluationLevel(Enum):
    """è¯„æµ‹ç­‰çº§"""
    EXCELLENT = "ä¼˜ç§€"
    GOOD = "è‰¯å¥½"
    PASS = "åˆæ ¼"
    FAIL = "ä¸åˆæ ¼"
    VETO = "ä¸€ç¥¨å¦å†³"  # å…³é”®ä»»åŠ¡æœªå®Œæˆ


@dataclass
class DimensionScore:
    """å•ä¸ªç»´åº¦çš„è¯„åˆ†"""
    dimension: str
    score: float  # 0-100
    weight: float
    level: str  # ä¼˜ç§€/è‰¯å¥½/åˆæ ¼/ä¸åˆæ ¼
    analysis: str  # è¯¦ç»†åˆ†æ
    evidence: List[str]  # æ”¯æ’‘è¯æ®
    issues: List[str]  # å‘ç°çš„é—®é¢˜
    suggestions: List[str]  # æ”¹è¿›å»ºè®®
    is_veto: bool = False  # æ˜¯å¦ä¸€ç¥¨å¦å†³
    
    @property
    def weighted_score(self) -> float:
        return self.score * self.weight


@dataclass
class EvaluationReport:
    """å®Œæ•´è¯„æµ‹æŠ¥å‘Š"""
    task_id: str
    total_score: float
    final_level: EvaluationLevel
    dimensions: List[DimensionScore]
    executive_summary: str  # é«˜ç®¡æ‘˜è¦
    critical_issues: List[str]  # å…³é”®é—®é¢˜
    actionable_suggestions: List[str]  # å¯æ‰§è¡Œå»ºè®®
    pass_criteria_met: bool  # æ˜¯å¦è¾¾åˆ°åˆæ ¼æ ‡å‡†
    veto_reasons: List[str] = field(default_factory=list)  # ä¸€ç¥¨å¦å†³åŸå› 


class LLMEvaluationAgent:
    """åŸºäºLLMçš„è¯„æµ‹Agent"""
    
    MAX_DIALOGUE_LENGTH = 15000  # æœ€å¤§å¯¹è¯å­—ç¬¦æ•°é™åˆ¶
    
    # è¯„æµ‹ç»´åº¦é…ç½®(æŒ‰ä½ çš„è¦æ±‚é‡æ–°è®¾è®¡)
    DIMENSIONS = {
        "teaching_goal_completion": {
            "name": "ç›®æ ‡è¾¾æˆåº¦",
            "weight": 0.40,  # æœ€é«˜æƒé‡
            "is_veto": True,  # ä¸€ç¥¨å¦å†³é¡¹
            "veto_threshold": 60  # ä½äº60åˆ†ç›´æ¥ä¸åˆæ ¼
        },
        "teaching_strategy": {
            "name": "ç­–ç•¥å¼•å¯¼åŠ›",
            "weight": 0.20,
            "is_veto": False
        },
        "workflow_consistency": {
            "name": "æµç¨‹éµå¾ªåº¦",
            "weight": 0.15,
            "is_veto": False
        },
        "interaction_experience": {
            "name": "äº¤äº’ä½“éªŒæ„Ÿ",
            "weight": 0.10,
            "is_veto": False
        },
        "hallucination_control": {
            "name": "å¹»è§‰æ§åˆ¶åŠ›",
            "weight": 0.10,
            "is_veto": False
        },
        "robustness": {
            "name": "å¼‚å¸¸å¤„ç†åŠ›",
            "weight": 0.05,
            "is_veto": False
        }
    }
    
    def __init__(self, 
                 teacher_doc_path: str, 
                 dialogue_json_path: str,
                 llm_api_key: Optional[str] = None,
                 llm_base_url: Optional[str] = None,
                 llm_model: str = "gpt-4o"):
        """
        åˆå§‹åŒ–LLMè¯„æµ‹Agent
        
        Args:
            teacher_doc_path: æ•™å¸ˆæ–‡æ¡£è·¯å¾„
            dialogue_json_path: å¯¹è¯è®°å½•JSONè·¯å¾„
            llm_api_key: LLM APIå¯†é’¥(å¦‚æœä¸ºNone,ä».envæ–‡ä»¶è¯»å–)
            llm_base_url: LLM APIåŸºç¡€URL(å¦‚æœä¸ºNone,ä».envæ–‡ä»¶è¯»å–)
            llm_model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.teacher_doc_path = teacher_doc_path
        self.dialogue_json_path = dialogue_json_path
        
        # åŠ è½½.envæ–‡ä»¶
        self._load_env_config()
        
        # LLMé…ç½®(ä¼˜å…ˆä½¿ç”¨å‚æ•°,å…¶æ¬¡ä½¿ç”¨.env,æœ€åä½¿ç”¨ç¯å¢ƒå˜é‡)
        self.llm_api_key = llm_api_key or self.env_config.get('LLM_API_KEY') or os.getenv('LLM_API_KEY')
        self.llm_base_url = llm_base_url or self.env_config.get('LLM_BASE_URL') or os.getenv('LLM_BASE_URL')
        self.llm_model = llm_model or self.env_config.get('LLM_MODEL', 'gpt-4o')
        
        if not self.llm_api_key:
            raise ValueError(
                "æœªæ‰¾åˆ°LLM APIå¯†é’¥ã€‚è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½® LLM_API_KEY "
                "æˆ–è®¾ç½®ç¯å¢ƒå˜é‡,æˆ–åœ¨åˆå§‹åŒ–æ—¶ä¼ å…¥ llm_api_key å‚æ•°"
            )
        
        if not self.llm_base_url:
            raise ValueError(
                "æœªæ‰¾åˆ°LLM APIåœ°å€ã€‚è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½® LLM_BASE_URL "
                "æˆ–è®¾ç½®ç¯å¢ƒå˜é‡,æˆ–åœ¨åˆå§‹åŒ–æ—¶ä¼ å…¥ llm_base_url å‚æ•°"
            )
        
        # åŠ è½½æ•°æ®
        self.teacher_doc = self._load_teacher_doc()
        self.dialogue_data = self._load_dialogue_json()
        
        print(f"âœ“ å·²åŠ è½½æ•™å¸ˆæ–‡æ¡£: {len(self.teacher_doc)} å­—ç¬¦")
        print(f"âœ“ å·²åŠ è½½å¯¹è¯è®°å½•: {self.dialogue_data['metadata']['total_rounds']} è½®")
        print(f"âœ“ LLMé…ç½®: {self.llm_base_url} / {self.llm_model}")
    
    def _load_env_config(self):
        """åŠ è½½.envæ–‡ä»¶é…ç½®"""
        self.env_config = {}
        
        # æŸ¥æ‰¾.envæ–‡ä»¶(å½“å‰ç›®å½•æˆ–ä¸Šçº§ç›®å½•)
        env_paths = [
            '.env',
            '../.env',
            '../../.env',
            os.path.join(os.path.dirname(__file__), '.env'),
            os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env')
        ]
        
        env_file = None
        for path in env_paths:
            if os.path.exists(path):
                env_file = path
                break
        
        if env_file:
            print(f"âœ“ æ‰¾åˆ°é…ç½®æ–‡ä»¶: {env_file}")
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
                    if not line or line.startswith('#'):
                        continue
                    # è§£æé”®å€¼å¯¹
                    if '=' in line:
                        key, value = line.split('=', 1)
                        # ç§»é™¤å¼•å·
                        value = value.strip().strip('"').strip("'")
                        self.env_config[key.strip()] = value
        else:
            print("âš ï¸ æœªæ‰¾åˆ°.envæ–‡ä»¶,å°†ä½¿ç”¨ç¯å¢ƒå˜é‡")
    
    def _load_teacher_doc(self) -> str:
        """åŠ è½½æ•™å¸ˆæ–‡æ¡£"""
        # å¦‚æœæ˜¯docx,å…ˆè½¬æ¢
        if self.teacher_doc_path.lower().endswith('.docx'):
            md_path = self._convert_docx_to_md(self.teacher_doc_path)
            with open(md_path, 'r', encoding='utf-8') as f:
                return f.read()
        else:
            with open(self.teacher_doc_path, 'r', encoding='utf-8') as f:
                return f.read()
    
    def _convert_docx_to_md(self, docx_path: str) -> str:
        """è½¬æ¢docxä¸ºmarkdown"""
        import subprocess
        
        base_name = os.path.splitext(os.path.basename(docx_path))[0]
        output_dir = os.path.dirname(docx_path) or '.'
        md_path = os.path.join(output_dir, f"{base_name}_converted.md")
        
        try:
            subprocess.run(
                ['pandoc', '--track-changes=all', docx_path, '-o', md_path],
                check=True,
                capture_output=True
            )
            print(f"âœ“ å·²å°†docxè½¬æ¢ä¸ºmarkdown: {md_path}")
            return md_path
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"Pandocè½¬æ¢å¤±è´¥: {e.stderr.decode()}")
        except FileNotFoundError:
            raise RuntimeError("æœªå®‰è£…pandocã€‚è¯·è¿è¡Œ: brew install pandoc")
    
    def _load_dialogue_json(self) -> Dict:
        """åŠ è½½å¯¹è¯è®°å½•"""
        with open(self.dialogue_json_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _call_llm(self, prompt: str, temperature: float = 0.3) -> str:
        """
        è°ƒç”¨LLM API
        
        Args:
            prompt: æç¤ºè¯
            temperature: æ¸©åº¦å‚æ•°(0-1,è¶Šä½è¶Šç¡®å®š)
            
        Returns:
            LLMè¿”å›çš„æ–‡æœ¬
        """
        try:
            import requests
            
            # æ„é€ è¯·æ±‚
            url = self.llm_base_url
            headers = {
                'api-key': self.llm_api_key,
                'Content-Type': 'application/json'
            }
            
            payload = {
                "maxTokens": 4000,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ•™å­¦è´¨é‡è¯„ä¼°ä¸“å®¶,æ“…é•¿åˆ†ææ•™å­¦æ™ºèƒ½ä½“çš„å¯¹è¯è´¨é‡ã€‚ä½ çš„è¯„ä»·å®¢è§‚ã€ä¸“ä¸šã€æœ‰å»ºè®¾æ€§ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "model": self.llm_model,
                "n": 1,
                "presence_penalty": 0.0,
                "temperature": temperature
            }
            
            # å‘é€POSTè¯·æ±‚
            #import pdb;pdb.set_trace()
            response = requests.post(url, headers=headers, json=payload, timeout=120)
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code != 200:
                raise RuntimeError(
                    f"APIè¯·æ±‚å¤±è´¥: HTTP {response.status_code}\n"
                    f"å“åº”å†…å®¹: {response.text[:500]}"
                )
            
            # è§£æå“åº”
            result = response.json()
            
            # æå–è¿”å›çš„å†…å®¹
            if 'choices' in result and len(result['choices']) > 0:
                content = result['choices'][0]['message']['content']
                
                # æ‰“å°tokenä½¿ç”¨æƒ…å†µ(å¦‚æœæœ‰)
                if 'usage' in result:
                    usage = result['usage']
                    print(f"   Tokenä½¿ç”¨: æç¤º{usage.get('prompt_tokens', 0)} + "
                          f"ç”Ÿæˆ{usage.get('completion_tokens', 0)} = "
                          f"æ€»è®¡{usage.get('total_tokens', 0)}")
                
                return content
            else:
                raise RuntimeError(f"APIè¿”å›æ ¼å¼å¼‚å¸¸: {result}")
            
        except requests.exceptions.Timeout:
            raise RuntimeError("APIè¯·æ±‚è¶…æ—¶(120ç§’),è¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åé‡è¯•")
        except requests.exceptions.ConnectionError:
            raise RuntimeError(f"æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨: {self.llm_base_url}")
        except Exception as e:
            raise RuntimeError(f"LLM APIè°ƒç”¨å¤±è´¥: {str(e)}")
    
    def _evaluate_dimension(self, dimension_key: str) -> DimensionScore:
        """
        è¯„æµ‹å•ä¸ªç»´åº¦
        
        Args:
            dimension_key: ç»´åº¦é”®å
            
        Returns:
            è¯¥ç»´åº¦çš„è¯„åˆ†ç»“æœ
        """
        config = self.DIMENSIONS[dimension_key]
        dimension_name = config['name']
        
        print(f"\nâ³ æ­£åœ¨è¯„æµ‹: {dimension_name}...")
        
        # æ„é€ ä¸“é—¨çš„è¯„æµ‹æç¤ºè¯
        prompt = self._build_dimension_prompt(dimension_key)
        
        # è°ƒç”¨LLMè¯„æµ‹
        llm_response = self._call_llm(prompt)
        
        # è§£æLLMè¿”å›çš„JSON
        result = self._parse_llm_response(llm_response)
        
        # æ„é€ è¯„åˆ†å¯¹è±¡
        score = DimensionScore(
            dimension=dimension_name,
            score=result['score'],
            weight=config['weight'],
            level=result['level'],
            analysis=result['analysis'],
            evidence=result['evidence'],
            issues=result['issues'],
            suggestions=result['suggestions'],
            is_veto=config.get('is_veto', False) and result['score'] < config.get('veto_threshold', 60)
        )
        
        print(f"âœ“ {dimension_name}: {score.score:.1f}åˆ† - {score.level}")
        
        return score
    
    def _build_dimension_prompt(self, dimension_key: str) -> str:
        """æ„é€ ç»´åº¦è¯„æµ‹çš„æç¤ºè¯"""
        
        config = self.DIMENSIONS[dimension_key]
        dimension_name = config['name']
        
        # å‡†å¤‡å¯¹è¯æ–‡æœ¬
        dialogue_text = self._format_dialogue_for_llm()
        
        # æ ¹æ®ä¸åŒç»´åº¦æ„é€ ä¸“é—¨çš„æç¤ºè¯
        prompts = {
            "teaching_goal_completion": f"""
# è¯„æµ‹ä»»åŠ¡:æ•™å­¦ç›®æ ‡ä¸ä»»åŠ¡å®Œæˆåº¦è¯„æµ‹

## è¯„æµ‹å¯¹è±¡
ä½ éœ€è¦è¯„æµ‹ä¸€ä¸ªæ•™å­¦æ™ºèƒ½ä½“ä¸å­¦ç”Ÿçš„å¯¹è¯,åˆ¤æ–­æ™ºèƒ½ä½“æ˜¯å¦æˆåŠŸå¼•å¯¼å­¦ç”Ÿå®Œæˆäº†æ•™å¸ˆæ–‡æ¡£ä¸­è§„å®šçš„å…¨éƒ¨æ•™å­¦ç›®æ ‡ã€‚

**è¿™æ˜¯ä¸€ç¥¨å¦å†³é¡¹!å¦‚æœæ ¸å¿ƒä»»åŠ¡æœªå®Œæˆ,æ— è®ºå¯¹è¯å¤šæµç•…,éƒ½ä¸èƒ½é€šè¿‡ã€‚**

## æ•™å¸ˆæ–‡æ¡£(æ ‡å‡†ç­”æ¡ˆ)
```markdown
{self.teacher_doc}
```

## å®é™…å¯¹è¯è®°å½•
```json
{dialogue_text}
```

## è¯„æµ‹è¦ç‚¹(è¯·é€é¡¹æ£€æŸ¥)

### 1. å…³é”®èƒ½åŠ›ç‚¹è¦†ç›–ç‡(40åˆ†)
- æ˜¯å¦è¦†ç›–æ–‡æ¡£ä¸­å®šä¹‰çš„**æ‰€æœ‰æ ¸å¿ƒçŸ¥è¯†ç‚¹å’Œæ“ä½œæ­¥éª¤**?
- æ¯ä¸ªç¯èŠ‚çš„å…³é”®å‚æ•°ã€æ ‡å‡†æ˜¯å¦éƒ½ä¼ è¾¾åˆ°ä½?
- æ˜¯å¦é—æ¼äº†ä»»ä½•å¿…è¦çš„æ•™å­¦å†…å®¹?

### 2. ä»»åŠ¡é¡ºåºä¸æµç¨‹å®Œæ•´æ€§(25åˆ†)
- æ˜¯å¦æŒ‰ç…§æ–‡æ¡£è§„å®šçš„é¡ºåºå¼•å¯¼å­¦ç”Ÿå®Œæˆä»»åŠ¡?
- æ¯ä¸ªç¯èŠ‚ä¹‹é—´çš„è¿‡æ¸¡æ˜¯å¦è‡ªç„¶åˆç†?
- æ˜¯å¦æœ‰è·³æ­¥ã€çœç•¥ã€æˆ–é¡ºåºé”™ä¹±?

### 3. ä¸»åŠ¨å¼•å¯¼ä¸èŠ‚ç‚¹æ¨è¿›(20åˆ†)
- åœ¨å…³é”®èŠ‚ç‚¹,æ™ºèƒ½ä½“æ˜¯å¦ä¸»åŠ¨å‘èµ·å¼•å¯¼?
- è¿˜æ˜¯è¢«åŠ¨ç­‰å¾…å­¦ç”Ÿæé—®?
- æ˜¯å¦èƒ½åœ¨å­¦ç”Ÿå¡å£³æ—¶ç»™å‡º**æ°å½“çš„æç¤º**(ä¸ç›´æ¥ç»™ç­”æ¡ˆ)?

### 4. ä»»åŠ¡æ”¶æ•›ä¸æ€»ç»“(15åˆ†)
- ä»»åŠ¡å®Œæˆå,æ˜¯å¦æœ‰æ˜ç¡®çš„æ”¶æ•›ä¸æ€»ç»“?
- æ˜¯å¦ç¡®è®¤å­¦ç”Ÿå·²ç†è§£æ‰€æœ‰è¦ç‚¹?
- æ˜¯å¦æœ‰"ä¸‹ä¸€æ­¥"çš„å¼•å¯¼æˆ–åæ€?

## è¾“å‡ºè¦æ±‚(ä¸¥æ ¼JSONæ ¼å¼)

```json
{{
  "score": 85,  // 0-100çš„åˆ†æ•°
  "level": "è‰¯å¥½",  // ä¼˜ç§€/è‰¯å¥½/åˆæ ¼/ä¸åˆæ ¼
  "analysis": "è¯¦ç»†åˆ†æ:æ™ºèƒ½ä½“å®Œæˆäº†æ–‡æ¡£ä¸­çš„5ä¸ªä¸»è¦ç¯èŠ‚...",
  "evidence": [
    "ç¯èŠ‚1'æ¯æ ªé€‰æ‹©'ä¸­,å®Œæ•´ä¼ è¾¾äº†3-5å¹´ç”Ÿã€ç›´å¾„1.0-1.5cmç­‰å…³é”®å‚æ•°",
    "ç¯èŠ‚2'ç¯å‰¥æ“ä½œ'ä¸­,å‡†ç¡®è¯´æ˜äº†æ·±åº¦è‡³æœ¨è´¨éƒ¨ã€å®½åº¦1.5å€ç­‰æ ‡å‡†",
    "..."
  ],
  "issues": [
    "é—æ¼äº†'é›¨å¤©æ£€æŸ¥é€æ°”å­”'è¿™ä¸€å…»æŠ¤è¦ç‚¹",
    "ç¬¬ä¸‰ç¯èŠ‚'åŸºè´¨åŒ…è£¹'ä¸­,æœªæ˜ç¡®æåŠé€æ°”å­”çš„å…·ä½“ä½ç½®è¦æ±‚",
    "..."
  ],
  "suggestions": [
    "è¡¥å……å®Œæ•´çš„å…»æŠ¤æ³¨æ„äº‹é¡¹æ¸…å•",
    "åœ¨åŸºè´¨åŒ…è£¹ç¯èŠ‚å¢åŠ é€æ°”å­”ä½ç½®çš„è¯¦ç»†è¯´æ˜",
    "..."
  ]
}}
```

**é‡è¦æé†’:**
- å¦‚æœå‘ç°**æ ¸å¿ƒä»»åŠ¡æœªå®Œæˆ**(å¦‚5ä¸ªç¯èŠ‚åªå®Œæˆ3ä¸ª),åˆ†æ•°åº”<60åˆ†
- å¦‚æœåªæ˜¯ç»†èŠ‚é—æ¼ä½†ä¸»ä½“å®Œæ•´,å¯ç»™70-80åˆ†
- å¦‚æœå…¨éƒ¨å®Œæˆä¸”è´¨é‡é«˜,å¯ç»™85-95åˆ†
- ä¸è¦ç»™100åˆ†,æ€»æœ‰æ”¹è¿›ç©ºé—´

è¯·ä¸¥æ ¼æŒ‰JSONæ ¼å¼è¾“å‡º,ä¸è¦æœ‰ä»»ä½•å¤šä½™çš„æ–‡å­—!
""",
            
            "teaching_strategy": f"""
# è¯„æµ‹ä»»åŠ¡:æ•™å­¦ç­–ç•¥ä¸å¼•å¯¼è´¨é‡è¯„æµ‹

## æ ¸å¿ƒç†å¿µ
**æ•™å­¦æ™ºèƒ½ä½“ â‰  ç™¾ç§‘é—®ç­”æœºå™¨äºº**

å¥½çš„æ•™å­¦ä¸æ˜¯ç›´æ¥ç»™ç­”æ¡ˆ,è€Œæ˜¯:
- å¼•å¯¼å­¦ç”Ÿæ€è€ƒ
- å¾ªåºæ¸è¿›åœ°å»ºç«‹çŸ¥è¯†ä½“ç³»
- å…è®¸è¯•é”™,åœ¨é”™è¯¯ä¸­å­¦ä¹ 
- é€šè¿‡è¿½é—®ä¿ƒè¿›æ·±åº¦ç†è§£

## æ•™å¸ˆæ–‡æ¡£
```markdown
{self.teacher_doc}
```

## å®é™…å¯¹è¯è®°å½•
```json
{dialogue_text}
```

## è¯„æµ‹è¦ç‚¹

### 1. å¼•å¯¼å¼æ•™å­¦è€Œéç›´æ¥ç»™ç­”æ¡ˆ(30åˆ†)
æ£€æŸ¥å¯¹è¯ä¸­:
- âŒ "ç­”æ¡ˆæ˜¯XXX" â†’ ç›´æ¥ç»™ç­”æ¡ˆ
- âœ… "ä½ è§‰å¾—åº”è¯¥é€‰æ‹©ä»€ä¹ˆæ ·çš„ææ¡?" â†’ å¼•å¯¼æé—®
- âœ… "æƒ³æƒ³çœ‹,ä¸ºä»€ä¹ˆè¦é€‰1-2å¹´ç”Ÿçš„ææ¡?" â†’ å¯å‘æ€è€ƒ

### 2. å¾ªåºæ¸è¿›,ç”±æµ…å…¥æ·±(25åˆ†)
- æ˜¯å¦ä»ç®€å•æ¦‚å¿µå¼€å§‹,é€æ­¥æ·±å…¥?
- æ˜¯å¦åœ¨å­¦ç”ŸæŒæ¡åŸºç¡€åæ‰å¼•å…¥å¤æ‚å†…å®¹?
- å‰åçŸ¥è¯†ç‚¹çš„è¡”æ¥æ˜¯å¦åˆç†?

### 3. è¿½é—®ä¸åé—®ä¿ƒè¿›æ€è€ƒ(25åˆ†)
- å½“å­¦ç”Ÿå›ç­”å,æ˜¯å¦æœ‰è¿½é—®"ä¸ºä»€ä¹ˆ"?
- æ˜¯å¦ç”¨åé—®æ¿€å‘å­¦ç”Ÿä¸»åŠ¨æ€è€ƒ?
- ä¾‹å¦‚:"ä½ è§‰å¾—è¿™æ ·åšçš„ç›®çš„æ˜¯ä»€ä¹ˆ?"

### 4. å…è®¸è¯•é”™ä¸çº é”™æŠ€å·§(20åˆ†)
- å­¦ç”Ÿç­”é”™æ—¶,æ˜¯å¦ç›´æ¥ç»™æ ‡å‡†ç­”æ¡ˆ?è¿˜æ˜¯å¼•å¯¼æ‰¾å‡ºé”™è¯¯åŸå› ?
- çº é”™æ—¶æ˜¯å¦è¯´æ˜åŸå› è€Œéç®€å•çº æ­£?
- æ˜¯å¦é¼“åŠ±å­¦ç”Ÿå†æ¬¡å°è¯•?

## è¾“å‡ºJSONæ ¼å¼

```json
{{
  "score": 75,
  "level": "è‰¯å¥½",
  "analysis": "æ™ºèƒ½ä½“æ•´ä½“é‡‡ç”¨å¼•å¯¼å¼æ•™å­¦...",
  "evidence": [
    "åœ¨ç¬¬2è½®å¯¹è¯ä¸­,ç”¨'è¯·è¯´æ˜æ¯æ ªå’Œææ¡çš„é€‰æ‹©æ ‡å‡†'å¼•å¯¼è€Œéç›´æ¥å‘ŠçŸ¥",
    "..."
  ],
  "issues": [
    "ç¬¬5è½®å­¦ç”Ÿå›ç­”é”™è¯¯å,ç›´æ¥ç»™å‡ºäº†æ ‡å‡†ç­”æ¡ˆ,æœªå¼•å¯¼å­¦ç”Ÿæ€è€ƒ",
    "ç¼ºå°‘'ä¸ºä»€ä¹ˆ'ç±»çš„æ·±åº¦è¿½é—®",
    "..."
  ],
  "suggestions": [
    "åœ¨å­¦ç”Ÿç­”é”™æ—¶,æ”¹ç”¨'ä½ è§‰å¾—å“ªé‡Œå¯èƒ½æœ‰é—®é¢˜'è¿™æ ·çš„å¼•å¯¼",
    "å¢åŠ è¿½é—®ç¯èŠ‚,å¦‚'ä¸ºä»€ä¹ˆè¦é€‰è¿™ä¸ªç›´å¾„èŒƒå›´'",
    "..."
  ]
}}
```

è¯·ä¸¥æ ¼æŒ‰JSONæ ¼å¼è¾“å‡º!
""",
            
            "workflow_consistency": f"""
# è¯„æµ‹ä»»åŠ¡:å¯¹è¯æµç¨‹ä¸€è‡´æ€§ä¸å·¥ä½œæµéµå¾ªåº¦

## è¯„æµ‹ç›®æ ‡
æ£€æŸ¥æ™ºèƒ½ä½“æ˜¯å¦ä¸¥æ ¼æŒ‰ç…§è®¾è®¡çš„å·¥ä½œæµè¿è¡Œ,æœ‰æ— å¼‚å¸¸çš„è·³æ­¥ã€å›é€€ã€å¾ªç¯ç­‰é—®é¢˜ã€‚

## æ•™å¸ˆæ–‡æ¡£(é¢„æœŸå·¥ä½œæµ)
```markdown
{self.teacher_doc}
```

## å®é™…å¯¹è¯è®°å½•
```json
{dialogue_text}
```

## è¯„æµ‹è¦ç‚¹

### 1. ç¯èŠ‚é¡ºåºæ­£ç¡®æ€§(35åˆ†)
- æ˜¯å¦æŒ‰æ–‡æ¡£è§„å®šçš„ç¯èŠ‚é¡ºåºæ‰§è¡Œ?
- æœ‰æ— è·³è¿‡æŸä¸ªç¯èŠ‚?
- æœ‰æ— ç¯èŠ‚é¡ºåºé¢ å€’?

### 2. è§’è‰²ä¸€è‡´æ€§(25åˆ†)
- æ™ºèƒ½ä½“æ˜¯å¦ä¿æŒäº†é¢„è®¾è§’è‰²(å¦‚"è¾…åŠ©å‘˜èŠè¯")?
- æœ‰æ— è§’è‰²æ··ä¹±æˆ–ä¸è¯¥å‡ºç°çš„è§’è‰²å‘è¨€?
- è§’è‰²è½¬æ¢æ˜¯å¦åˆç†?

### 3. æµç¨‹æ”¶æ•›æ€§(25åˆ†)
- æ¯ä¸ªç¯èŠ‚æ˜¯å¦æœ‰æ˜ç¡®çš„ç»“æŸæ ‡å¿—?
- æ˜¯å¦åœ¨å®Œæˆåæ‰è¿›å…¥ä¸‹ä¸€ç¯èŠ‚?
- æœ‰æ— åœ¨ç»“æŸèŠ‚ç‚¹åä»ç»§ç»­æ— å…³å¯¹è¯?

### 4. å¼‚å¸¸çŠ¶æ€å¤„ç†(15åˆ†)
- å‡ºç°å¼‚å¸¸è¾“å…¥æ—¶,æ˜¯å¦èƒ½å›åˆ°ä¸»æµç¨‹?
- æœ‰æ— æ­»å¾ªç¯ã€æ— é™è¿½é—®?
- æ˜¯å¦èƒ½ä»åç¦»ä¸­æ¢å¤?

## è¾“å‡ºJSONæ ¼å¼

```json
{{
  "score": 88,
  "level": "è‰¯å¥½",
  "analysis": "å·¥ä½œæµæ‰§è¡ŒåŸºæœ¬è§„èŒƒ,5ä¸ªç¯èŠ‚æŒ‰åºå®Œæˆ...",
  "evidence": [
    "ç¯èŠ‚1â†’2â†’3â†’4â†’5çš„é¡ºåºå®Œå…¨ç¬¦åˆæ–‡æ¡£",
    "æ¯ä¸ªç¯èŠ‚ç»“æŸæ—¶éƒ½æœ‰æ˜ç¡®çš„'è¾¾æ ‡'/'å¯è¿›å…¥ä¸‹ä¸€ç¯èŠ‚'æ ‡è®°",
    "..."
  ],
  "issues": [
    "ç¬¬3è½®å’Œç¬¬4è½®ä¹‹é—´å‡ºç°äº†çŸ­æš‚çš„è¯é¢˜åç¦»",
    "ç¯èŠ‚4ä¸­æœ‰ä¸€æ¬¡å›é€€åˆ°ç¯èŠ‚3çš„å†…å®¹",
    "..."
  ],
  "suggestions": [
    "å¢å¼ºç¯èŠ‚é—´çš„è¿‡æ¸¡æ§åˆ¶,é¿å…è¯é¢˜åç¦»",
    "..."
  ]
}}
```
""",
            
            "interaction_experience": f"""
# è¯„æµ‹ä»»åŠ¡:è¯­è¨€ä¸äº¤äº’ä½“éªŒ

## è¯„æµ‹é‡ç‚¹
è¿™é‡Œä¸è¿½æ±‚æ–‡å­¦æ€§,è€Œæ˜¯**æ•™å­¦å¯ç”¨æ€§**ã€‚

## å¯¹è¯è®°å½•
```json
{dialogue_text}
```

## è¯„æµ‹è¦ç‚¹

### 1. è¡¨è¾¾æ¸…æ™°åº¦(30åˆ†)
- æŒ‡ä»¤æ˜¯å¦æ˜ç¡®,æ— æ­§ä¹‰?
- ä¸“ä¸šæœ¯è¯­æ˜¯å¦è§£é‡Šåˆ°ä½?
- å­¦ç”Ÿèƒ½å¦å‡†ç¡®ç†è§£æ„å›¾?

### 2. æœºæ¢°æ„Ÿä¸æ¨¡æ¿åŒ–(25åˆ†)
- æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„æ¨¡æ¿ç—•è¿¹?
- è¯­è¨€æ˜¯å¦è¿‡äºç¨‹å¼åŒ–?
- æ˜¯å¦æœ‰é‡å¤ä½¿ç”¨ç›¸åŒå¥å¼?

### 3. ä¸Šä¸‹æ–‡ç†è§£(25åˆ†)
- èƒ½å¦æ­£ç¡®ç†è§£å­¦ç”Ÿçš„æŒ‡ä»£("è¿™ä¸ª"ã€"å®ƒ")?
- èƒ½å¦æ‰¿æ¥ä¸Šä¸€è½®å¯¹è¯çš„å†…å®¹?
- æœ‰æ— ç­”éæ‰€é—®çš„æƒ…å†µ?

### 4. è¯­æ°”é€‚é…æ€§(20åˆ†)
- è¯­æ°”æ˜¯å¦ç¬¦åˆæ•™å­¦åœºæ™¯?
- æ˜¯å¦è¿‡äºéšæ„æˆ–è¿‡äºå†·æ¼ ?
- é¼“åŠ±ä¸çº é”™çš„è¯­æ°”æ˜¯å¦æ°å½“?

## è¾“å‡ºJSONæ ¼å¼

```json
{{
  "score": 82,
  "level": "è‰¯å¥½",
  "analysis": "è¯­è¨€è¡¨è¾¾æ•´ä½“æ¸…æ™°,ç¬¦åˆæ•™å­¦åœºæ™¯...",
  "evidence": [
    "ç¬¬5è½®å¯¹çº é”™æ—¶è¯­æ°”å§”å©‰:'éœ€è°ƒæ•´'è€Œé'é”™è¯¯'",
    "..."
  ],
  "issues": [
    "å¤šæ¬¡å‡ºç°'è¯·æŒ‰ç…§è¦æ±‚...'çš„æ¨¡æ¿åŒ–è¡¨è¾¾",
    "ç¬¬8è½®æœªèƒ½ç†è§£å­¦ç”Ÿçš„'é‚£ä¸ª'æŒ‡ä»£",
    "..."
  ],
  "suggestions": [
    "å‡å°‘æ¨¡æ¿åŒ–ç”¨è¯­,å¢åŠ è¡¨è¾¾å¤šæ ·æ€§",
    "..."
  ]
}}
```
""",
            
            "hallucination_control": f"""
# è¯„æµ‹ä»»åŠ¡:å¹»è§‰ä¸ä¸å½“è¾“å‡ºæ§åˆ¶

## æ•™å¸ˆæ–‡æ¡£(çŸ¥è¯†è¾¹ç•Œ)
```markdown
{self.teacher_doc}
```

## å¯¹è¯è®°å½•
```json
{dialogue_text}
```

## è¯„æµ‹è¦ç‚¹

### 1. çŸ¥è¯†å‡†ç¡®æ€§(40åˆ†)
- æ˜¯å¦å¼•ç”¨äº†ä¸å­˜åœ¨çš„æ¦‚å¿µ/å·¥å…·?
- å‚æ•°ã€æ•°å€¼æ˜¯å¦ä¸æ–‡æ¡£ä¸€è‡´?
- æœ‰æ— è‡ªè¡Œç¼–é€ çš„"æ ‡å‡†"?

### 2. æ–‡æ¡£ä¸€è‡´æ€§(30åˆ†)
- æ˜¯å¦ä¸æ•™å¸ˆæ–‡æ¡£å†²çª?
- æ˜¯å¦ç»™å‡ºäº†æ–‡æ¡£ä¸­æ²¡æœ‰çš„æ“ä½œæ­¥éª¤?
- æœ‰æ— è¶…å‡ºæ–‡æ¡£èŒƒå›´çš„æ‰©å±•?

### 3. æƒé™è¾¹ç•Œ(20åˆ†)
- æ˜¯å¦è¶Šæƒæ·»åŠ äº†æ•™å­¦ç›®æ ‡?
- æ˜¯å¦æ“…è‡ªä¿®æ”¹äº†è¯„ä¼°æ ‡å‡†?
- æ˜¯å¦ä¿æŒåœ¨"è¾…åŠ©å‘˜"è§’è‰²å†…?

### 4. è‡ªä¿¡åº¦æ ¡å‡†(10åˆ†)
- ä¸ç¡®å®šæ—¶æ˜¯å¦æ‰¿è®¤ä¸ç¡®å®š?
- è¿˜æ˜¯é”™äº†ä¹Ÿå¾ˆè‡ªä¿¡?

## è¾“å‡ºJSONæ ¼å¼

```json
{{
  "score": 65,
  "level": "åˆæ ¼",
  "analysis": "å­˜åœ¨ä¸€äº›å‚æ•°ä¸ä¸€è‡´å’Œè¶…çº²å†…å®¹...",
  "evidence": [
    "ç¯èŠ‚2ä¸­ç”Ÿæ ¹å‰‚æµ“åº¦ä¸æ–‡æ¡£ä¸€è‡´(2000mg/L)",
    "..."
  ],
  "issues": [
    "æåˆ°äº†'å¤šèŒçµæº¶æ¶²é¢„é˜²éœ‰èŒ',ä½†æ–‡æ¡£ä¸­æœªæ¶‰åŠç—…è™«å®³é˜²æ²»",
    "åŸºè´¨æ¹¿åº¦è¯´äº†'60%-70%'ä½†æ–‡æ¡£è¦æ±‚æ˜¯'70%-80%'",
    "..."
  ],
  "suggestions": [
    "ä¸¥æ ¼å¯¹ç…§æ–‡æ¡£,ä¸æ·»åŠ æ–‡æ¡£å¤–å†…å®¹",
    "æ‰€æœ‰å‚æ•°éƒ½éœ€ä¸æ–‡æ¡£å®Œå…¨ä¸€è‡´",
    "..."
  ]
}}
```
""",
            
            "robustness": f"""
# è¯„æµ‹ä»»åŠ¡:é²æ£’æ€§ä¸å¼‚å¸¸å¤„ç†èƒ½åŠ›

## å¯¹è¯è®°å½•
```json
{dialogue_text}
```

## è¯„æµ‹è¦ç‚¹

### 1. åç¦»åçš„æ¢å¤èƒ½åŠ›(30åˆ†)
- å­¦ç”Ÿä¸æŒ‰é¢„æœŸå›ç­”æ—¶,èƒ½å¦æ‹‰å›ä¸»çº¿?
- å­¦ç”Ÿç­”éæ‰€é—®æ—¶,å¦‚ä½•çº å?
- æ¢å¤çš„æ–¹å¼æ˜¯å¦è‡ªç„¶?

### 2. é‡å¤é—®é¢˜å¤„ç†(25åˆ†)
- å­¦ç”Ÿé‡å¤æé—®,æ˜¯å¦æœ‰è€å¿ƒ?
- ä¼šä¸ä¼šç»™å‡ºå®Œå…¨ç›¸åŒçš„å›ç­”?
- æ˜¯å¦æ¢ä¸ªè§’åº¦é‡æ–°è§£é‡Š?

### 3. å¾ªç¯é¿å…(25åˆ†)
- æœ‰æ— æ­»å¾ªç¯(åå¤é—®åŒä¸€é—®é¢˜)?
- æœ‰æ— é™·å…¥æ— æ„ä¹‰çš„å¯¹è¯?
- æ˜¯å¦èƒ½ä¸»åŠ¨æ‰“ç ´åƒµå±€?

### 4. è¶Šç•Œè¯·æ±‚å¤„ç†(20åˆ†)
- å­¦ç”Ÿç›´æ¥è¦ç­”æ¡ˆ,å¦‚ä½•å¤„ç†?
- å­¦ç”Ÿè¦æ±‚åšæ–‡æ¡£å¤–çš„äº‹,å¦‚ä½•æ‹’ç»?
- æ‹’ç»æ—¶æ˜¯å¦ç»™å‡ºåˆç†è§£é‡Š?

## è¾“å‡ºJSONæ ¼å¼

```json
{{
  "score": 70,
  "level": "åˆæ ¼",
  "analysis": "åŸºæœ¬å…·å¤‡å¼‚å¸¸å¤„ç†èƒ½åŠ›,ä½†æŸäº›æƒ…å†µä¸‹è¡¨ç°ä¸å¤Ÿç¨³å®š...",
  "evidence": [
    "åœ¨å­¦ç”Ÿå›ç­”ç®€çŸ­æ—¶,èƒ½å¤Ÿç»§ç»­å¼•å¯¼è€Œéå¡ä½",
    "..."
  ],
  "issues": [
    "æœªæ£€æµ‹åˆ°å­¦ç”Ÿé‡å¤æé—®çš„æƒ…å†µ,æ— æ³•è¯„ä¼°",
    "å­¦ç”Ÿä¸€æ¬¡å›ç­”è¿‡äºç®€ç•¥,æ™ºèƒ½ä½“æœªè¿½é—®",
    "..."
  ],
  "suggestions": [
    "å¢åŠ å¯¹å­¦ç”Ÿå¼‚å¸¸è¾“å…¥çš„è¯†åˆ«å’Œå¤„ç†",
    "..."
  ]
}}
```
"""
        }
        
        return prompts.get(dimension_key, "")
    
    def _format_dialogue_for_llm(self) -> str:
        """æ ¼å¼åŒ–å¯¹è¯è®°å½•ä¸ºLLMå¯è¯»æ ¼å¼"""
        formatted = []
        
        for stage in self.dialogue_data['stages']:
            formatted.append(f"\n## {stage['stage_name']}\n")
            
            for msg in stage['messages']:
                role = "æ™ºèƒ½ä½“" if msg['role'] == 'assistant' else "å­¦ç”Ÿ"
                formatted.append(f"**{role}(ç¬¬{msg['round']}è½®):** {msg['content']}\n")
        
        return "\n".join(formatted)
    
    def _parse_llm_response(self, response: str) -> Dict:
        """è§£æLLMè¿”å›çš„JSON"""
        try:
            # æ¸…ç†å¯èƒ½çš„markdownä»£ç å—
            response = response.strip()
            if response.startswith('```json'):
                response = response[7:]
            if response.startswith('```'):
                response = response[3:]
            if response.endswith('```'):
                response = response[:-3]
            response = response.strip()
            
            # è§£æJSON
            result = json.loads(response)
            
            # éªŒè¯å¿…è¦å­—æ®µ
            required_fields = ['score', 'level', 'analysis', 'evidence', 'issues', 'suggestions']
            for field in required_fields:
                if field not in result:
                    raise ValueError(f"LLMè¿”å›ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
            
            return result
            
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response[:500]}...")
            # è¿”å›é»˜è®¤å€¼
            return {
                'score': 50,
                'level': 'åˆæ ¼',
                'analysis': f'JSONè§£æå¤±è´¥,ä½¿ç”¨é»˜è®¤åˆ†æ•°ã€‚é”™è¯¯: {str(e)}',
                'evidence': [],
                'issues': ['LLMè¿”å›æ ¼å¼é”™è¯¯'],
                'suggestions': ['éœ€è¦ä¿®å¤LLMæç¤ºè¯æˆ–å“åº”è§£æ']
            }
    
    def evaluate(self) -> EvaluationReport:
        """
        æ‰§è¡Œå®Œæ•´è¯„æµ‹
        
        Returns:
            å®Œæ•´çš„è¯„æµ‹æŠ¥å‘Š
        """
        print("\n" + "="*70)
        print("å¼€å§‹LLMé©±åŠ¨çš„æ™ºèƒ½ä½“è¯„æµ‹")
        print("="*70)
        
        dimension_scores = []
        veto_reasons = []
        
        # æŒ‰é¡ºåºè¯„æµ‹å„ç»´åº¦
        for dimension_key in self.DIMENSIONS.keys():
            score = self._evaluate_dimension(dimension_key)
            dimension_scores.append(score)
            
            # æ£€æŸ¥ä¸€ç¥¨å¦å†³
            if score.is_veto:
                veto_reasons.append(
                    f"{score.dimension}å¾—åˆ†{score.score:.1f}åˆ†,ä½äº{self.DIMENSIONS[dimension_key]['veto_threshold']}åˆ†é˜ˆå€¼"
                )
        
        # è®¡ç®—æ€»åˆ†
        total_score = sum(s.weighted_score for s in dimension_scores)
        
        # ç¡®å®šæœ€ç»ˆç­‰çº§
        if veto_reasons:
            final_level = EvaluationLevel.VETO
            pass_criteria_met = False
        elif total_score >= 90:
            final_level = EvaluationLevel.EXCELLENT
            pass_criteria_met = True
        elif total_score >= 75:
            final_level = EvaluationLevel.GOOD
            pass_criteria_met = True
        elif total_score >= 60:
            final_level = EvaluationLevel.PASS
            pass_criteria_met = True
        else:
            final_level = EvaluationLevel.FAIL
            pass_criteria_met = False
        
        # ç”Ÿæˆé«˜ç®¡æ‘˜è¦
        executive_summary = self._generate_executive_summary(
            dimension_scores, total_score, final_level, veto_reasons
        )
        
        # æå–å…³é”®é—®é¢˜å’Œå»ºè®®
        critical_issues = self._extract_critical_issues(dimension_scores)
        actionable_suggestions = self._extract_actionable_suggestions(dimension_scores)
        
        report = EvaluationReport(
            task_id=self.dialogue_data['metadata']['task_id'],
            total_score=total_score,
            final_level=final_level,
            dimensions=dimension_scores,
            executive_summary=executive_summary,
            critical_issues=critical_issues,
            actionable_suggestions=actionable_suggestions,
            pass_criteria_met=pass_criteria_met,
            veto_reasons=veto_reasons
        )
        
        print("\n" + "="*70)
        print(f"è¯„æµ‹å®Œæˆ!æ€»åˆ†: {total_score:.1f} - {final_level.value}")
        print("="*70)
        
        return report
    
    def _generate_executive_summary(self, 
                                    dimensions: List[DimensionScore],
                                    total_score: float,
                                    level: EvaluationLevel,
                                    veto_reasons: List[str]) -> str:
        """ç”Ÿæˆé«˜ç®¡æ‘˜è¦"""
        lines = [
            f"## è¯„æµ‹ç»“è®º: {level.value} ({total_score:.1f}/100)",
            ""
        ]
        
        if veto_reasons:
            lines.append("### âš ï¸ ä¸€ç¥¨å¦å†³åŸå› ")
            for reason in veto_reasons:
                lines.append(f"- {reason}")
            lines.append("")
        
        lines.append("### å„ç»´åº¦å¾—åˆ†")
        for dim in dimensions:
            emoji = "âœ…" if dim.score >= 80 else "âš ï¸" if dim.score >= 60 else "âŒ"
            lines.append(
                f"{emoji} **{dim.dimension}**: {dim.weighted_score:.1f}/{dim.weight*100:.0f} "
            )
        
        lines.append("")
        lines.append("### æ ¸å¿ƒå‘ç°")
        
        # æœ€é«˜åˆ†ç»´åº¦
        best_dim = max(dimensions, key=lambda d: d.score)
        lines.append(f"- âœ¨ **ä¼˜åŠ¿**: {best_dim.dimension}è¡¨ç°æœ€å¥½")
        
        # æœ€ä½åˆ†ç»´åº¦
        worst_dim = min(dimensions, key=lambda d: d.score)
        lines.append(f"- ğŸ”§ **å¾…æ”¹è¿›**: {worst_dim.dimension}éœ€è¦é‡ç‚¹ä¼˜åŒ–")
        
        return "\n".join(lines)
    
    def _extract_critical_issues(self, dimensions: List[DimensionScore]) -> List[str]:
        """æå–å…³é”®é—®é¢˜"""
        critical = []
        
        for dim in dimensions:
            if dim.score < 60:  # ä¸åˆæ ¼çš„ç»´åº¦
                critical.extend([f"ã€{dim.dimension}ã€‘{issue}" for issue in dim.issues])
            elif dim.score < 75:  # åˆæ ¼ä½†éœ€æ”¹è¿›çš„ç»´åº¦
                # åªå–å‰2ä¸ªæœ€é‡è¦çš„é—®é¢˜
                critical.extend([f"ã€{dim.dimension}ã€‘{issue}" for issue in dim.issues[:2]])
        
        return critical
    
    def _extract_actionable_suggestions(self, dimensions: List[DimensionScore]) -> List[str]:
        """æå–å¯æ‰§è¡Œå»ºè®®(æŒ‰ä¼˜å…ˆçº§)"""
        suggestions = []
        
        # æŒ‰åˆ†æ•°ä»ä½åˆ°é«˜æ’åº,ä¼˜å…ˆæ”¹è¿›ä½åˆ†é¡¹
        sorted_dims = sorted(dimensions, key=lambda d: d.score)
        
        for dim in sorted_dims:
            if dim.suggestions:
                # ä¸ºæ¯æ¡å»ºè®®æ·»åŠ ç»´åº¦æ ‡ç­¾ï¼Œæœ€å¤šå–å‰3æ¡
                for suggestion in dim.suggestions[:3]:
                    # æ¸…ç†å»ºè®®æ–‡æœ¬ï¼Œç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œç¼–å·
                    clean_suggestion = suggestion.strip()
                    # å¦‚æœå»ºè®®å·²ç»ä»¥æ•°å­—å¼€å¤´ï¼ˆå¦‚"1."ï¼‰ï¼Œåˆ™ç§»é™¤å®ƒ
                    if clean_suggestion and clean_suggestion[0].isdigit():
                        parts = clean_suggestion.split('.', 1)
                        if len(parts) > 1:
                            clean_suggestion = parts[1].strip()
                    if clean_suggestion:
                        suggestions.append(f"ã€{dim.dimension}ã€‘{clean_suggestion}")
        
        return suggestions
    
    def generate_report(self, output_path: str = None) -> str:
        """
        ç”Ÿæˆè¯„æµ‹æŠ¥å‘Š
        
        Args:
            output_path: è¾“å‡ºè·¯å¾„(å¯é€‰)
            
        Returns:
            æŠ¥å‘Šæ–‡æœ¬
        """
        report = self.evaluate()
        
        lines = [
            "="*80,
            "åŸºäºLLMçš„å®è®­æ™ºèƒ½ä½“è¯„æµ‹æŠ¥å‘Š",
            "="*80,
            "",
            f"ä»»åŠ¡ID: {report.task_id}",
            f"è¯„æµ‹æ—¶é—´: {self.dialogue_data['metadata']['workflow_start_time']}",
            f"å­¦ç”Ÿç±»å‹: {self.dialogue_data['metadata'].get('student_profile_label', 'æœªçŸ¥')}",
            f"å¯¹è¯è½®æ¬¡: {self.dialogue_data['metadata']['total_rounds']}",
            "",
            "="*80,
            report.executive_summary,
            "",
            "="*80,
            "è¯¦ç»†åˆ†æ",
            "="*80,
            ""
        ]
        
        # å„ç»´åº¦è¯¦æƒ…
        for dim in report.dimensions:
            lines.extend([
                f"### {dim.dimension}",
                f"**å¾—åˆ†**: {dim.weighted_score:.1f}/{dim.weight*100:.0f} ",
                f"**ç­‰çº§**: {dim.level}",
                "",
                f"**åˆ†æ**:",
                dim.analysis,
                "",
                f"**æ”¯æ’‘è¯æ®**:",
            ])
            for evidence in dim.evidence:
                lines.append(f"  âœ“ {evidence}")
            
            lines.append("")
            lines.append(f"**å‘ç°çš„é—®é¢˜**:")
            for issue in dim.issues:
                lines.append(f"  âœ— {issue}")
            
            lines.append("")
            lines.append(f"**æ”¹è¿›å»ºè®®**:")
            for suggestion in dim.suggestions:
                lines.append(f"  â†’ {suggestion}")
            
            lines.append("")
            lines.append("-"*80)
            lines.append("")
        
        # å…³é”®é—®é¢˜æ±‡æ€»
        lines.extend([
            "="*80,
            "å…³é”®é—®é¢˜æ±‡æ€»",
            "="*80,
            ""
        ])
        for issue in report.critical_issues:
            lines.append(f"â€¢ {issue}")
        
        # å¯æ‰§è¡Œå»ºè®®
        lines.extend([
            "",
            "="*80,
            "å¯æ‰§è¡Œå»ºè®®(æŒ‰ä¼˜å…ˆçº§)",
            "="*80,
            ""
        ])
        for suggestion in report.actionable_suggestions:
            lines.append(suggestion)
        
        # æœ€ç»ˆç»“è®º
        lines.extend([
            "",
            "="*80,
            "æœ€ç»ˆç»“è®º",
            "="*80,
            f"",
            f"æ€»åˆ†: {report.total_score:.1f}/100",
            f"ç­‰çº§: {report.final_level.value}",
            f"æ˜¯å¦åˆæ ¼: {'âœ… æ˜¯' if report.pass_criteria_met else 'âŒ å¦'}",
            ""
        ])
        
        if report.veto_reasons:
            lines.append("âš ï¸ ä¸€ç¥¨å¦å†³åŸå› :")
            for reason in report.veto_reasons:
                lines.append(f"  â€¢ {reason}")
        
        lines.extend([
            "",
            "="*80,
            "è¯„æµ‹å®Œæˆ",
            "="*80
        ])
        
        report_text = "\n".join(lines)
        
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_text)
            print(f"\nâœ“ æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
        
        return report_text


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python llm_evaluation_agent.py <æ•™å¸ˆæ–‡æ¡£> <å¯¹è¯è®°å½•.json> [API_KEY]")
        print("\næˆ–è®¾ç½®ç¯å¢ƒå˜é‡:")
        print("  export OPENAI_API_KEY=your_key")
        print("  export OPENAI_BASE_URL=https://api.openai.com/v1  # å¯é€‰")
        sys.exit(1)
    
    teacher_doc = sys.argv[1]
    dialogue_json = sys.argv[2]
    api_key = sys.argv[3] if len(sys.argv) > 3 else None
    
    try:
        agent = LLMEvaluationAgent(
            teacher_doc_path=teacher_doc,
            dialogue_json_path=dialogue_json,
            llm_api_key=api_key
        )
        
        output_path = dialogue_json.replace('.json', '_llm_evaluation.txt')
        agent.generate_report(output_path)
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
