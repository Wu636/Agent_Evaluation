import asyncio
import json
import json.decoder
import os
import tempfile
import time
import uuid
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Optional

import requests
from dotenv import load_dotenv

# æœ¬åœ°è§£ææ¨¡å—ï¼ˆè·³è¿‡äº‘ç«¯ APIï¼‰
try:
    from local_parser import parse_word_to_text_input
    LOCAL_PARSER_AVAILABLE = True
except ImportError:
    LOCAL_PARSER_AVAILABLE = False

# LLM ç­”æ¡ˆæ ¡éªŒæ¨¡å—
try:
    from llm_answer_corrector import async_correct_answers_with_llm
    LLM_CORRECTOR_AVAILABLE = True
except ImportError:
    LLM_CORRECTOR_AVAILABLE = False


def load_env_config():
    """
    åŠ è½½.envé…ç½®æ–‡ä»¶ï¼Œä¼˜å…ˆåŠ è½½å½“å‰ç›®å½•ä¸‹çš„.envæ–‡ä»¶
    å¦‚æœå½“å‰ç›®å½•æ²¡æœ‰ï¼Œåˆ™åŠ è½½ä¸Šçº§ç›®å½•çš„.envæ–‡ä»¶
    """
    current_dir = Path(__file__).parent

    # ä¼˜å…ˆå°è¯•åŠ è½½å½“å‰ç›®å½•ä¸‹çš„.envæ–‡ä»¶
    local_env = current_dir / '.env'
    if local_env.exists():
        load_dotenv(local_env)
        print(f"âœ… ä»æœ¬åœ°ç›®å½•åŠ è½½.envé…ç½®: {local_env}")
        return local_env

    # å¦‚æœå½“å‰ç›®å½•æ²¡æœ‰ï¼Œå°è¯•åŠ è½½ä¸Šçº§ç›®å½•çš„.envæ–‡ä»¶
    parent_env = current_dir.parent / '.env'
    if parent_env.exists():
        load_dotenv(parent_env)
        print(f"âœ… ä»ä¸Šçº§ç›®å½•åŠ è½½.envé…ç½®: {parent_env}")
        return parent_env

    # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»å½“å‰å·¥ä½œç›®å½•åŠ è½½
    cwd_env = Path.cwd() / '.env'
    if cwd_env.exists():
        load_dotenv(cwd_env)
        print(f"âœ… ä»å·¥ä½œç›®å½•åŠ è½½.envé…ç½®: {cwd_env}")
        return cwd_env

    raise FileNotFoundError("æœªæ‰¾åˆ°.envé…ç½®æ–‡ä»¶ï¼Œè¯·åœ¨å½“å‰ç›®å½•æˆ–ä¸Šçº§ç›®å½•åˆ›å»º.envæ–‡ä»¶")


def safe_json_loads(value):
    if isinstance(value, (dict, list)):
        return value
    if isinstance(value, str):
        try:
            return json.loads(value)
        except json.JSONDecodeError:
            return None
    return None


def extract_writing_requirement(detail: dict) -> str:
    business_config = safe_json_loads(detail.get("businessConfig"))
    writing_requirement = ""
    if isinstance(business_config, dict):
        composition = business_config.get("compositionRequirement") or {}
        writing_requirement = composition.get("writingRequirement") or ""
        if not writing_requirement:
            requirement_file = composition.get("requirementFile") or {}
            writing_requirement = requirement_file.get("content") or ""
    if not writing_requirement:
        writing_requirement = detail.get("desc") or ""
    return writing_requirement


def fetch_instance_details(instance_nid: str):
    """é€šè¿‡ agent/details æ¥å£è·å–ä½œä¸šä¿¡æ¯"""
    url = "https://cloudapi.polymas.com/agents/v1/agent/details"

    authorization = os.getenv('AUTHORIZATION')
    cookie = os.getenv('COOKIE')
    if not authorization:
        print("âŒ æœªæ‰¾åˆ°AUTHORIZATIONç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®AUTHORIZATION")
        return None
    if not cookie:
        print("âŒ æœªæ‰¾åˆ°COOKIEç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®COOKIE")
        return None

    headers = {
        "Content-Type": "application/json; charset=utf-8",
        "Authorization": authorization,
        "Cookie": cookie,
    }

    payload = {
        "instanceIds": [instance_nid],
        "needToToolSchema": False
    }

    try:
        response = requests.post(
            url,
            headers=headers,
            data=json.dumps(payload, ensure_ascii=False).encode('utf-8')
        )
        result = response.json()
    except json.decoder.JSONDecodeError:
        print(f"âŒ è·å–ä½œä¸šä¿¡æ¯å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
        print("å“åº”å†…å®¹ï¼ˆéJSONæ ¼å¼ï¼Œå¯èƒ½ä¸ºæœåŠ¡ç«¯é”™è¯¯é¡µï¼‰ï¼š", response.text)
        return None
    except Exception as e:
        print(f"âŒ è·å–ä½œä¸šä¿¡æ¯å¼‚å¸¸ï¼š{str(e)}")
        return None

    if not result.get('success'):
        print(f"âŒ è·å–ä½œä¸šä¿¡æ¯å¤±è´¥ï¼š{result.get('msg')}")
        return None

    instance_details = result.get('data', {}).get('instanceDetails', [])
    if not instance_details:
        print("âŒ è·å–ä½œä¸šä¿¡æ¯å¤±è´¥ï¼šinstanceDetails ä¸ºç©º")
        return None

    detail = instance_details[0] or {}
    user_id = detail.get('userId')
    agent_id = detail.get('agentNid') or detail.get('agentId')
    if not user_id:
        print("âŒ è·å–ä½œä¸šä¿¡æ¯å¤±è´¥ï¼šå“åº”ä¸­æœªæ‰¾åˆ° userId")
        return None
    if not agent_id:
        print("âŒ è·å–ä½œä¸šä¿¡æ¯å¤±è´¥ï¼šå“åº”ä¸­æœªæ‰¾åˆ° agentNid")
        return None

    writing_requirement = extract_writing_requirement(detail)

    return {
        "user_id": user_id,
        "agent_id": agent_id,
        "instance_name": detail.get("instanceName", ""),
        "desc": detail.get("desc", ""),
        "writing_requirement": writing_requirement,
        "version": detail.get("version") or 2,
    }


def ensure_instance_context():
    """é€šè¿‡æ¥å£è·å–å®ä¾‹ä¿¡æ¯ï¼ˆä»…å½“å‰è¿›ç¨‹ä½¿ç”¨ï¼Œä¸å†™å›.envï¼‰"""
    instance_nid = os.getenv('INSTANCE_NID', '').strip().strip('"').strip("'")
    if not instance_nid:
        print("âŒ æœªæ‰¾åˆ°INSTANCE_NIDç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®INSTANCE_NID")
        return None

    details = fetch_instance_details(instance_nid)
    if not details:
        return None

    user_id = details.get("user_id") or os.getenv("USER_ID", "").strip().strip('"').strip("'")
    agent_id = details.get("agent_id") or os.getenv("AGENT_ID", "").strip().strip('"').strip("'")
    if not user_id:
        print("âŒ æœªè·å–åˆ° userIdï¼Œè¯·æ£€æŸ¥ INSTANCE_NID æ˜¯å¦æ­£ç¡®")
        return None
    if not agent_id:
        print("âŒ æœªè·å–åˆ° agentIdï¼Œè¯·æ£€æŸ¥ INSTANCE_NID æ˜¯å¦æ­£ç¡®")
        return None

    print(f"âœ… å·²è·å–USER_ID: {user_id}")
    print(f"âœ… å·²è·å–AGENT_ID: {agent_id}")

    return {
        "instance_nid": instance_nid,
        "user_id": user_id,
        "agent_id": agent_id,
        "writing_requirement": details.get("writing_requirement", ""),
        "version": details.get("version") or 2,
        "instance_name": details.get("instance_name", ""),
        "desc": details.get("desc", ""),
    }


def upload_file(file_path):
    """
    ä¸Šä¼ æ–‡ä»¶åˆ°æœåŠ¡å™¨

    Args:
        file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„

    Returns:
        dict: åŒ…å« fileName å’Œ fileUrl çš„å­—å…¸ï¼Œå¦‚æœä¸Šä¼ å¤±è´¥è¿”å› None
    """
    url = "https://cloudapi.polymas.com/basic-resource/file/upload"

    # ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç 
    identify_code = str(uuid.uuid4())

    try:
        # æ‰“å¼€æ–‡ä»¶
        with open(file_path, 'rb') as f:
            # è·å–æ–‡ä»¶åå’Œå¤§å°
            file_name = os.path.basename(file_path)
            file_size = os.path.getsize(file_path)

            # æ ¹æ®æ–‡ä»¶æ‰©å±•ååˆ¤æ–­ MIME ç±»å‹
            file_ext = os.path.splitext(file_name)[1].lower()
            mime_types = {
                '.png': 'image/png',
                '.jpg': 'image/jpeg',
                '.jpeg': 'image/jpeg',
                '.gif': 'image/gif',
                '.pdf': 'application/pdf',
                '.doc': 'application/msword',
                '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            }
            mime_type = mime_types.get(file_ext, 'application/octet-stream')

            # å‡†å¤‡è¡¨å•æ•°æ®
            files = {
                'file': (file_name, f, mime_type)
            }

            data = {
                'identifyCode': identify_code,
                'name': file_name,
                'chunk': '0',
                'chunks': '1',
                'size': str(file_size)
            }

            # ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–é…ç½®
            authorization = os.getenv('AUTHORIZATION')
            cookie = os.getenv('COOKIE')

            if not authorization:
                raise ValueError("æœªæ‰¾åˆ°AUTHORIZATIONç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®AUTHORIZATION")
            if not cookie:
                raise ValueError("æœªæ‰¾åˆ°COOKIEç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®COOKIE")

            headers = {
                'Authorization': authorization,
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36',
                'Cookie': cookie
            }

            # å‘é€è¯·æ±‚
            print(f"â³ æ­£åœ¨ä¸Šä¼ æ–‡ä»¶: {file_name}")
            response = requests.post(url, headers=headers, data=data, files=files)
            result = response.json()

            if result.get('success'):
                data = result.get('data', {})
                file_url = data.get('ossUrl')
                print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file_name}")
                return {
                    'fileName': file_name,
                    'fileUrl': file_url
                }
            else:
                print(f"âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {file_name}, é”™è¯¯ä¿¡æ¯: {result.get('msg')}")
                return None

    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None
    except Exception as e:
        print(f"âŒ ä¸Šä¼ æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {file_path}, é”™è¯¯: {str(e)}")
        return None


def is_success_response(result: dict) -> bool:
    if not isinstance(result, dict):
        return False
    if "success" in result:
        return bool(result.get("success"))
    return result.get("code") == 200


def fetch_task_result(task_id: str, context: dict):
    """è½®è¯¢è·å–ä»»åŠ¡ç»“æœ"""
    url = "https://cloudapi.polymas.com/agents/v1/get/task"

    authorization = os.getenv('AUTHORIZATION')
    cookie = os.getenv('COOKIE')
    if not authorization:
        return False, {"error": "æœªæ‰¾åˆ°AUTHORIZATIONç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®AUTHORIZATION"}
    if not cookie:
        return False, {"error": "æœªæ‰¾åˆ°COOKIEç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®COOKIE"}

    headers = {
        "Content-Type": "application/json; charset=utf-8",
        "Authorization": authorization,
        "Cookie": cookie
    }

    payload = {
        "taskId": task_id,
        "metadata": {
            "instanceNid": context.get("instance_nid", "")
        }
    }

    try:
        response = requests.post(
            url,
            headers=headers,
            data=json.dumps(payload, ensure_ascii=False).encode('utf-8')
        )
        try:
            result = response.json()
        except json.decoder.JSONDecodeError:
            return False, {
                "status_code": response.status_code,
                "text": response.text
            }

        return is_success_response(result), result

    except Exception as e:
        return False, {"error": str(e)}


def poll_task_until_complete(task_id: str, context: dict, interval_seconds: int = 2, timeout_seconds: int = 300):
    start_time = time.monotonic()
    last_result = None

    while True:
        success, result = fetch_task_result(task_id, context)
        last_result = result

        if success and isinstance(result, dict):
            data = result.get("data") or {}
            if isinstance(data, dict):
                if data.get("artifacts"):
                    return True, result
                status = data.get("status") or {}
                state = status.get("state")
                if state == "completed":
                    return True, result
                if state in {"failed", "error", "cancelled"}:
                    return False, result
        else:
            return False, result

        if time.monotonic() - start_time >= timeout_seconds:
            return False, {
                "error": "ä»»åŠ¡è¶…æ—¶",
                "taskId": task_id,
                "last_response": last_result
            }

        time.sleep(interval_seconds)


def normalize_text_input(raw_data) -> Optional[str]:
    parsed = raw_data
    if isinstance(raw_data, str):
        try:
            parsed = json.loads(raw_data)
        except json.JSONDecodeError:
            return raw_data

    if isinstance(parsed, dict) and "content" in parsed:
        items = parsed.get("content") or []
        return json.dumps(_normalize_content_items(items), ensure_ascii=False)

    if isinstance(parsed, list):
        return json.dumps(_normalize_content_items(parsed), ensure_ascii=False)

    if isinstance(parsed, dict):
        return json.dumps(parsed, ensure_ascii=False)

    return str(parsed) if parsed is not None else None


def _normalize_content_items(items) -> list:
    normalized = []
    if not isinstance(items, list):
        return normalized

    for item in items:
        if isinstance(item, dict):
            normalized.append(
                {
                    "itemId": item.get("itemId") or item.get("item_id") or "",
                    "itemName": item.get("itemName") or item.get("item_name") or "",
                    "stuAnswerContent": item.get("stuAnswerContent")
                    or item.get("stu_answer_content")
                    or item.get("content")
                    or "",
                }
            )
        else:
            normalized.append(
                {
                    "itemId": "",
                    "itemName": "",
                    "stuAnswerContent": str(item),
                }
            )

    return normalized


def homework_file_analysis(file_info: dict, context: dict):
    """è°ƒç”¨ homeworkFileAnalysis æ¥å£è§£æä½œä¸šæ–‡ä»¶"""
    url = "https://cloudapi.polymas.com/agents/v1/file/homeworkFileAnalysis"

    authorization = os.getenv('AUTHORIZATION')
    cookie = os.getenv('COOKIE')
    if not authorization:
        return False, {"error": "æœªæ‰¾åˆ°AUTHORIZATIONç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®AUTHORIZATION"}, None
    if not cookie:
        return False, {"error": "æœªæ‰¾åˆ°COOKIEç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®COOKIE"}, None

    headers = {
        "Content-Type": "application/json; charset=utf-8",
        "Authorization": authorization,
        "Cookie": cookie
    }

    payload = {
        "agentId": context.get("agent_id", ""),
        "instanceNid": context.get("instance_nid", ""),
        "userNid": context.get("user_id", ""),
        "version": context.get("version") or 2,
        "writingRequirement": context.get("writing_requirement", ""),
        "activeMode": "upload",
        "editorContent": "",
        "fileList": [file_info],
    }

    try:
        response = requests.post(
            url,
            headers=headers,
            data=json.dumps(payload, ensure_ascii=False).encode('utf-8')
        )

        try:
            result = response.json()
        except json.decoder.JSONDecodeError:
            return False, {
                "status_code": response.status_code,
                "text": response.text
            }, None

        if not is_success_response(result):
            return False, result, None

        text_input = normalize_text_input(result.get("data"))
        if not text_input:
            return False, {"error": "è§£ææˆåŠŸä½†æœªæå–åˆ°å¯ç”¨çš„ textInput", "response": result}, None

        return True, result, text_input

    except Exception as e:
        return False, {"error": str(e)}, None


def execute_agent_text(text_input: str, context: dict):
    """è°ƒç”¨ agent API æ‰§è¡Œä½œä¸šæ‰¹æ”¹ï¼ˆTEXT_INPUTï¼‰"""
    url = "https://cloudapi.polymas.com/agents/v1/execute/agent"

    authorization = os.getenv('AUTHORIZATION')
    cookie = os.getenv('COOKIE')
    if not authorization:
        return False, {"error": "æœªæ‰¾åˆ°AUTHORIZATIONç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®AUTHORIZATION"}
    if not cookie:
        return False, {"error": "æœªæ‰¾åˆ°COOKIEç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®COOKIE"}

    headers = {
        "Content-Type": "application/json; charset=utf-8",
        "Authorization": authorization,
        "Cookie": cookie
    }

    user_id = context.get("user_id") or os.getenv("USER_ID", "")
    instance_nid = context.get("instance_nid") or os.getenv("INSTANCE_NID", "")
    if not user_id:
        return False, {"error": "æœªè·å–åˆ°userIdï¼Œè¯·æ£€æŸ¥INSTANCE_NID"}
    if not instance_nid:
        return False, {"error": "æœªè·å–åˆ°instanceNidï¼Œè¯·æ£€æŸ¥INSTANCE_NID"}

    if not isinstance(text_input, str):
        text_input = json.dumps(text_input, ensure_ascii=False)

    payload = {
        "metadata": {
            "dimension": "NONE",
            "instanceNid": instance_nid,
            "userIds": [user_id],
            "version": context.get("version") or 2,
            "async": True
        },
        "sendParams": {
            "message": {
                "kind": "message",
                "parts": [
                    {
                        "kind": "data",
                        "data": {
                            "writingRequirement": context.get("writing_requirement", ""),
                            "fileList": None,
                            "textInput": text_input,
                            "submitType": "TEXT_INPUT"
                        }
                    }
                ]
            }
        }
    }

    try:
        response = requests.post(
            url,
            headers=headers,
            data=json.dumps(payload, ensure_ascii=False).encode('utf-8')
        )

        try:
            result = response.json()
        except json.decoder.JSONDecodeError:
            return False, {
                "status_code": response.status_code,
                "text": response.text
            }

        return is_success_response(result), result

    except Exception as e:
        return False, {"error": str(e)}


def execute_agent_text_with_poll(text_input: str, context: dict, interval_seconds: int = 2, timeout_seconds: int = 300):
    success, result = execute_agent_text(text_input, context)
    if not success:
        return False, result

    data = result.get("data") if isinstance(result, dict) else None
    if isinstance(data, dict) and data.get("kind") == "task":
        task_id = data.get("id")
        if not task_id:
            return False, {"error": "æœªè·å–åˆ°taskId", "response": result}
        return poll_task_until_complete(task_id, context, interval_seconds, timeout_seconds)

    return success, result


def normalize_input_path(path_str: str) -> Path:
    """è§„èŒƒåŒ–ç”¨æˆ·è¾“å…¥è·¯å¾„"""
    path_str = path_str.strip().strip('"').strip("'")
    path = Path(path_str).expanduser()
    if not path.is_absolute():
        path = Path.cwd() / path
    return path


def collect_files_from_folder(folder_path: Path):
    """ä»æ–‡ä»¶å¤¹ä¸­æ”¶é›†æ–‡ä»¶ï¼ˆå¿½ç•¥éšè—æ–‡ä»¶ï¼‰"""
    if not folder_path.exists() or not folder_path.is_dir():
        return []
    return sorted([p for p in folder_path.iterdir() if p.is_file() and not p.name.startswith('.')])


def save_analysis_result(output_dir: Path, file_info: dict, result: dict, text_input: str):
    """ä¿å­˜ homeworkFileAnalysis ç»“æœ"""
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / "analysis.json"
    payload = {
        "fileName": file_info.get("fileName"),
        "fileUrl": file_info.get("fileUrl"),
        "savedAt": datetime.now().isoformat(timespec="seconds"),
        "textInput": text_input,
        "response": result
    }
    output_path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding='utf-8')
    return output_path


def save_result(output_dir: Path, file_info: dict, attempt_index: int, attempt_total: int, success: bool, result: dict):
    """ä¿å­˜æµ‹è¯„ç»“æœåˆ°æ–‡ä»¶"""
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / f"attempt_{attempt_index:02d}.json"
    payload = {
        "fileName": file_info.get("fileName"),
        "fileUrl": file_info.get("fileUrl"),
        "attempt": attempt_index,
        "attemptTotal": attempt_total,
        "success": success,
        "savedAt": datetime.now().isoformat(timespec="seconds"),
        "response": result
    }
    output_path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding='utf-8')
    return output_path


def load_pdf_generator():
    """åŠ¨æ€åŠ è½½ PDF ç”Ÿæˆæ¨¡å—ï¼ˆé¿å…ä½œä¸ºåŒ…å¯¼å…¥ï¼‰"""
    primary = Path(__file__).parent / "generate_report.py"
    fallback = Path(__file__).parent / "test" / "generate_report.py"
    report_path = primary if primary.exists() else fallback
    if not report_path.exists():
        print(f"âŒ æœªæ‰¾åˆ°PDFç”Ÿæˆè„šæœ¬: {primary} æˆ– {fallback}")
        return None

    import importlib.util

    spec = importlib.util.spec_from_file_location("generate_report", report_path)
    if not spec or not spec.loader:
        print("âŒ æ— æ³•åŠ è½½PDFç”Ÿæˆè„šæœ¬")
        return None
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module


def generate_pdf_report(result: dict, output_path: Path):
    """æ ¹æ®æ¥å£è¿”å›ç»“æœç”ŸæˆPDFæŠ¥å‘Š"""
    try:
        module = load_pdf_generator()
        if not module:
            return False
    except SystemExit as exc:
        print(f"âŒ PDFä¾èµ–ç¼ºå¤±ï¼š{exc}")
        return False
    except Exception as exc:
        print(f"âŒ åŠ è½½PDFç”Ÿæˆæ¨¡å—å¤±è´¥ï¼š{exc}")
        return False

    output_path.parent.mkdir(parents=True, exist_ok=True)

    try:
        with tempfile.NamedTemporaryFile(
            mode="w",
            suffix=".json",
            delete=False,
            encoding="utf-8",
            dir=output_path.parent
        ) as tmp:
            tmp.write(json.dumps(result, ensure_ascii=False, indent=2))
            tmp_path = Path(tmp.name)

        module.generate_pdf(str(tmp_path), str(output_path))
        tmp_path.unlink(missing_ok=True)
        return True
    except Exception as exc:
        print(f"âŒ ç”ŸæˆPDFå¤±è´¥ï¼š{exc}")
        return False


def can_generate_pdf(result: dict) -> bool:
    if not isinstance(result, dict):
        return False
    data = result.get("data")
    return isinstance(data, dict) and "artifacts" in data


def save_output(output_dir: Path, file_info: dict, attempt_index: int, attempt_total: int, success: bool, result: dict, output_format: str):
    """æ ¹æ®è¾“å‡ºæ ¼å¼ä¿å­˜ç»“æœ"""
    if output_format == "pdf":
        if not success or not can_generate_pdf(result):
            reason = result.get("msg") or result.get("error")
            status_code = result.get("status_code")
            code = result.get("code")
            trace_id = result.get("traceId")
            extra = []
            if status_code:
                extra.append(f"status={status_code}")
            if code:
                extra.append(f"code={code}")
            if trace_id:
                extra.append(f"traceId={trace_id}")
            if reason:
                extra.append(f"reason={reason}")
            detail = f" ({', '.join(extra)})" if extra else ""
            print(f"âš ï¸ ç»“æœå¤±è´¥æˆ–ä¸æ”¯æŒPDFï¼Œè·³è¿‡PDFç”Ÿæˆ: {file_info.get('fileName')}{detail}")
            return None
        output_path = output_dir / f"attempt_{attempt_index:02d}.pdf"
        ok = generate_pdf_report(result, output_path)
        return output_path if ok else None

    return save_result(output_dir, file_info, attempt_index, attempt_total, success, result)


def extract_category_from_name(name: str) -> str:
    """ä»é¢˜ç›®åç§°æå–ç±»å‹ï¼Œå¦‚ 'å•é¡¹é€‰æ‹©é¢˜ç¬¬1é¢˜' â†’ 'å•é¡¹é€‰æ‹©é¢˜'"""
    import re
    if not name:
        return ""
    # åŒ¹é…å¸¸è§é¢˜å‹ï¼šå•é¡¹é€‰æ‹©é¢˜ã€åˆ¤æ–­é¢˜ã€ç®€ç­”é¢˜ã€è®ºè¿°é¢˜ã€æ¡ˆä¾‹åˆ†æé¢˜ç­‰
    match = re.match(r'^([\u4e00-\u9fa5]+é¢˜)', name)
    if match:
        return match.group(1)
    # å¤„ç†ç‰¹æ®Šæ ¼å¼å¦‚ "æ¡ˆä¾‹åˆ†æé¢˜ç¬¬1é—®"
    if "æ¡ˆä¾‹åˆ†æ" in name:
        return "æ¡ˆä¾‹åˆ†æé¢˜"
    return ""


def calculate_category_scores(question_scores: list) -> dict:
    """æŒ‰é¢˜ç›®ç±»å‹åˆ†ç»„ç»Ÿè®¡å¾—åˆ†"""
    category_scores = {}  # {"å•é¡¹é€‰æ‹©é¢˜": {"score": 18, "total": 20}, ...}
    category_order = []  # ä¿æŒé¢˜å‹å‡ºç°é¡ºåº
    
    for q in question_scores:
        if not isinstance(q, dict):
            continue
        name = q.get("name", "")
        category = extract_category_from_name(name)
        if not category:
            continue
        
        if category not in category_scores:
            category_scores[category] = {"score": 0, "total": 0}
            category_order.append(category)
        
        category_scores[category]["score"] += q.get("score", 0) or 0
        category_scores[category]["total"] += q.get("totalScore", 0) or 0
    
    return {"scores": category_scores, "order": category_order}


def extract_core_data(result: dict) -> Optional[dict]:
    """ä»æ¥å£å“åº”ä¸­æå–æ ¸å¿ƒè¯„åˆ†æ•°æ®"""
    if not isinstance(result, dict):
        return None

    report_data = result.get("data", result)
    if isinstance(report_data, dict) and "artifacts" in report_data:
        artifacts = report_data.get("artifacts") or []
        if artifacts:
            parts = artifacts[0].get("parts") or []
            if parts:
                core_data = parts[0].get("data", {})
            else:
                core_data = {}
        else:
            core_data = {}
    else:
        core_data = report_data if isinstance(report_data, dict) else {}

    if not isinstance(core_data, dict):
        return None

    # è®¡ç®—åˆ†ç±»å¾—åˆ†
    question_scores = core_data.get("questionScores", [])
    category_data = calculate_category_scores(question_scores)

    return {
        "total_score": core_data.get("totalScore"),
        "full_mark": core_data.get("fullMark", 100),
        "dimension_scores": core_data.get("dimensionScores", []),
        "category_scores": category_data.get("scores", {}),
        "category_order": category_data.get("order", []),
    }


def resolve_summary_output_root(file_paths, output_root: Optional[Path]) -> Path:
    if output_root:
        return output_root
    parents = {path.parent.resolve() for path in file_paths}
    if len(parents) == 1:
        return next(iter(parents)) / "review_results"
    return Path.cwd() / "review_results"


def generate_excel_summary(summary_items, file_paths, attempts: int, output_root: Optional[Path]):
    try:
        from openpyxl import Workbook
        from openpyxl.styles import Alignment, Font
        from openpyxl.utils import get_column_letter
    except ImportError:
        print("âŒ æœªæ‰¾åˆ° openpyxlï¼Œæ— æ³•ç”ŸæˆExcelè¯„åˆ†è¡¨ã€‚è¯·å…ˆå®‰è£…: pip install openpyxl")
        return None

    output_root = resolve_summary_output_root(file_paths, output_root)
    output_root.mkdir(parents=True, exist_ok=True)

    label_counts = defaultdict(int)
    label_by_path = {}
    for path in file_paths:
        key = str(path)
        if key not in label_by_path:
            base = path.stem
            label_counts[base] += 1
            label = base if label_counts[base] == 1 else f"{base}({label_counts[base]})"
            label_by_path[key] = label

    score_data = {}
    order_by_label = {}
    category_order_by_label = {}  # åˆ†ç±»é¢˜å‹é¡ºåº

    for item in summary_items:
        if not item or not item.get("success"):
            continue
        core_data = extract_core_data(item.get("result", {}))
        if not core_data:
            continue
        file_path = item.get("file_path", "")
        label = label_by_path.get(file_path, Path(file_path).stem if file_path else "æœªå‘½å")
        entry = score_data.setdefault(
            label,
            {
                "full_mark": core_data.get("full_mark", 100),
                "total_scores": [None] * attempts,
                "dimensions": {},
                "categories": {},  # æ–°å¢ï¼šåˆ†ç±»å¾—åˆ†
            },
        )
        order = order_by_label.setdefault(label, [])
        category_order = category_order_by_label.setdefault(label, [])

        attempt_index = item.get("attempt_index", 0)
        if 1 <= attempt_index <= attempts:
            entry["total_scores"][attempt_index - 1] = core_data.get("total_score")

            # å¤„ç†åˆ†ç±»å¾—åˆ†
            category_scores = core_data.get("category_scores", {})
            for cat_name in core_data.get("category_order", []):
                if cat_name not in category_order:
                    category_order.append(cat_name)
                cat_data = category_scores.get(cat_name, {})
                cat_entry = entry["categories"].setdefault(
                    cat_name,
                    {"scores": [None] * attempts, "total": cat_data.get("total", 0)}
                )
                cat_entry["scores"][attempt_index - 1] = cat_data.get("score")
                # æ›´æ–°æ»¡åˆ†å€¼ï¼ˆå–æœ€å¤§å€¼ï¼‰
                if cat_data.get("total", 0) > cat_entry["total"]:
                    cat_entry["total"] = cat_data.get("total", 0)

            for dim in core_data.get("dimension_scores", []):
                name = dim.get("evaluationDimension") or "æœªå‘½åç»´åº¦"
                if name not in order:
                    order.append(name)
                scores = entry["dimensions"].setdefault(name, [None] * attempts)
                scores[attempt_index - 1] = dim.get("dimensionScore")

    if not score_data:
        print("âš ï¸ æœªè·å–åˆ°å¯ç”¨äºç”Ÿæˆè¯„åˆ†è¡¨çš„ç»“æœ")
        return None

    wb = Workbook()
    ws = wb.active
    ws.title = "è¯„åˆ†è¡¨"

    headers = ["æ¡£æ¬¡/å­¦ç”Ÿ", "è¯„ä»·ç»´åº¦"] + [f"ç¬¬{i}æ¬¡" for i in range(1, attempts + 1)] + ["å‡å€¼", "æ–¹å·®"]
    ws.append(headers)
    for col_idx in range(1, len(headers) + 1):
        cell = ws.cell(row=1, column=col_idx)
        cell.font = Font(bold=True)
        cell.alignment = Alignment(horizontal="center", vertical="center")

    row_idx = 2
    
    # æŒ‰ç­‰çº§é¡ºåºæ’åºï¼šä¼˜ç§€ã€è‰¯å¥½ã€ä¸­ç­‰ã€åˆæ ¼ã€è¾ƒå·®
    level_order = {"ä¼˜ç§€": 1, "è‰¯å¥½": 2, "ä¸­ç­‰": 3, "åˆæ ¼": 4, "è¾ƒå·®": 5}
    
    def get_level_priority(path):
        label = label_by_path.get(str(path), "")
        for level, priority in level_order.items():
            if level in label:
                return priority
        return 999  # æœªåŒ¹é…çš„æ”¾æœ€å
    
    sorted_paths = sorted(file_paths, key=get_level_priority)
    
    for path in sorted_paths:
        label = label_by_path.get(str(path))
        if label not in score_data:
            continue
        entry = score_data[label]
        order = order_by_label.get(label, [])
        category_order = category_order_by_label.get(label, [])

        full_mark = entry.get("full_mark", 100)
        try:
            full_mark_text = str(int(full_mark))
        except (TypeError, ValueError):
            full_mark_text = str(full_mark)
        total_label = f"æ€»åˆ†ï¼ˆ{full_mark_text}åˆ†ï¼‰" if full_mark_text else "æ€»åˆ†"

        ws.cell(row=row_idx, column=1).value = label
        ws.cell(row=row_idx, column=2).value = total_label
        total_scores = entry.get("total_scores", [])
        for idx, score in enumerate(total_scores, start=3):
            ws.cell(row=row_idx, column=idx).value = score
        # æ·»åŠ å‡å€¼å’Œæ–¹å·®
        valid_scores = [s for s in total_scores if s is not None]
        if valid_scores:
            mean_val = sum(valid_scores) / len(valid_scores)
            variance_val = sum((x - mean_val) ** 2 for x in valid_scores) / len(valid_scores) if len(valid_scores) > 1 else 0
            ws.cell(row=row_idx, column=3 + attempts).value = round(mean_val, 2)
            ws.cell(row=row_idx, column=4 + attempts).value = round(variance_val, 2)
        row_idx += 1

        # è¾“å‡ºåˆ†ç±»å¾—åˆ†ï¼ˆåœ¨æ€»åˆ†åï¼‰
        for cat_name in category_order:
            cat_entry = entry["categories"].get(cat_name, {})
            cat_total = cat_entry.get("total", 0)
            try:
                cat_total_text = str(int(cat_total))
            except (TypeError, ValueError):
                cat_total_text = str(cat_total)
            cat_label = f"{cat_name}ï¼ˆ{cat_total_text}åˆ†ï¼‰" if cat_total_text else cat_name
            
            ws.cell(row=row_idx, column=1).value = ""
            ws.cell(row=row_idx, column=2).value = cat_label
            cat_scores = cat_entry.get("scores", [None] * attempts)
            for idx, score in enumerate(cat_scores, start=3):
                ws.cell(row=row_idx, column=idx).value = score
            # æ·»åŠ å‡å€¼å’Œæ–¹å·®
            valid_scores = [s for s in cat_scores if s is not None]
            if valid_scores:
                mean_val = sum(valid_scores) / len(valid_scores)
                variance_val = sum((x - mean_val) ** 2 for x in valid_scores) / len(valid_scores) if len(valid_scores) > 1 else 0
                ws.cell(row=row_idx, column=3 + attempts).value = round(mean_val, 2)
                ws.cell(row=row_idx, column=4 + attempts).value = round(variance_val, 2)
            row_idx += 1

        for dim_name in order:
            ws.cell(row=row_idx, column=1).value = ""
            ws.cell(row=row_idx, column=2).value = dim_name
            scores = entry["dimensions"].get(dim_name, [None] * attempts)
            for idx, score in enumerate(scores, start=3):
                ws.cell(row=row_idx, column=idx).value = score
            # æ·»åŠ å‡å€¼å’Œæ–¹å·®
            valid_scores = [s for s in scores if s is not None]
            if valid_scores:
                mean_val = sum(valid_scores) / len(valid_scores)
                variance_val = sum((x - mean_val) ** 2 for x in valid_scores) / len(valid_scores) if len(valid_scores) > 1 else 0
                ws.cell(row=row_idx, column=3 + attempts).value = round(mean_val, 2)
                ws.cell(row=row_idx, column=4 + attempts).value = round(variance_val, 2)
            row_idx += 1

        row_idx += 1

    for col_idx in range(1, len(headers) + 1):
        column_letter = get_column_letter(col_idx)
        ws.column_dimensions[column_letter].width = 18 if col_idx <= 2 else 12

    output_path = output_root / "è¯„åˆ†è¡¨.xlsx"
    wb.save(output_path)
    print(f"âœ… è¯„åˆ†è¡¨å·²ç”Ÿæˆ: {output_path}")
    return output_path


async def async_upload_file(file_path: str, semaphore: asyncio.Semaphore):
    async with semaphore:
        return await asyncio.to_thread(upload_file, file_path)


async def async_homework_analysis(file_info: dict, context: dict, semaphore: asyncio.Semaphore):
    async with semaphore:
        return await asyncio.to_thread(homework_file_analysis, file_info, context)


async def async_execute_agent_text(text_input: str, context: dict, semaphore: asyncio.Semaphore):
    async with semaphore:
        return await asyncio.to_thread(execute_agent_text_with_poll, text_input, context)


async def evaluate_and_save(file_path: Path, file_info: dict, text_input: str, context: dict, output_dir: Path, attempt_index: int, attempt_total: int, output_format: str, semaphore: asyncio.Semaphore):
    print(f"â³ æ‰¹æ”¹ä¸­: {file_info['fileName']} ({attempt_index}/{attempt_total})")
    
    # æ‰¹æ”¹é‡è¯•æœºåˆ¶ï¼ˆå¢å¼ºç‰ˆ - 5æ¬¡é‡è¯• + æŒ‡æ•°é€€é¿ï¼‰
    max_retries = 5
    base_delay = 3  # åŸºç¡€å»¶è¿Ÿç§’æ•°
    success = False
    result = None
    
    for retry in range(max_retries):
        success, result = await async_execute_agent_text(text_input, context, semaphore)
        
        if success:
            break
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¯é‡è¯•çš„é”™è¯¯
        error_msg = str(result.get("error", "")) if isinstance(result, dict) else str(result)
        error_msg_lower = error_msg.lower()
        is_retryable = any(keyword in error_msg for keyword in [
            "SSLError", "ConnectionError", "TimeoutError", "Max retries exceeded",
            "EOF occurred", "Connection reset", "Connection refused",
            "BadStatusLine", "RemoteDisconnected", "BrokenPipeError",
            "ChunkedEncodingError", "IncompleteRead",
        ]) or any(keyword in error_msg_lower for keyword in [
            "rate limit", "too many requests", "429",
            "500", "502", "503", "504",
            "internal server error", "bad gateway", "service unavailable", "gateway timeout",
            "network", "timeout", "connection", "reset", "broken pipe",
        ])
        
        if is_retryable and retry < max_retries - 1:
            # æŒ‡æ•°é€€é¿ï¼š3s, 6s, 12s, 24s
            delay = base_delay * (2 ** retry)
            print(f"ğŸ”„ æ‰¹æ”¹é‡è¯• ({retry + 1}/{max_retries - 1}): {file_info['fileName']} ({attempt_index}/{attempt_total}) - ç­‰å¾…{delay}s")
            print(f"   åŸå› : {error_msg[:200]}")
            await asyncio.sleep(delay)
        else:
            if retry > 0:
                print(f"âŒ é‡è¯•{retry}æ¬¡åä»å¤±è´¥: {file_info['fileName']} ({attempt_index}/{attempt_total})")
            break
    
    output_path = save_output(output_dir, file_info, attempt_index, attempt_total, success, result, output_format)
    if output_path:
        print(f"âœ… å®Œæˆ: {file_info['fileName']} ({attempt_index}/{attempt_total}) -> {output_path}")
    else:
        print(f"âš ï¸ å®Œæˆ: {file_info['fileName']} ({attempt_index}/{attempt_total}) -> æœªç”Ÿæˆæ–‡ä»¶")
    return {
        "file_path": str(file_path),
        "attempt_index": attempt_index,
        "attempt_total": attempt_total,
        "success": success,
        "result": result,
    }


async def run_batch(file_paths, attempts: int, context: dict, output_root: Optional[Path], output_format: str, max_concurrency: int = 5, local_parse: bool = False):
    semaphore = asyncio.Semaphore(max_concurrency)

    upload_tasks = [async_upload_file(str(path), semaphore) for path in file_paths]
    upload_results = await asyncio.gather(*upload_tasks)

    file_infos = []
    for path, result in zip(file_paths, upload_results):
        if result:
            file_infos.append((path, result))

    if not file_infos:
        print("\nâŒ æ²¡æœ‰æˆåŠŸä¸Šä¼ çš„æ–‡ä»¶ï¼Œæ— æ³•æ‰§è¡Œæ‰¹æ”¹")
        return

    print(f"\nâœ… æˆåŠŸä¸Šä¼  {len(file_infos)} ä¸ªæ–‡ä»¶ï¼Œå…± {len(file_paths)} ä¸ª")

    # è§£ææ–‡ä»¶
    prepared_files = []
    
    if local_parse and LOCAL_PARSER_AVAILABLE:
        # æœ¬åœ°è§£ææ¨¡å¼ï¼ˆè·³è¿‡äº‘ç«¯ APIï¼‰
        print("\nğŸ“ ä½¿ç”¨æœ¬åœ°è§£ææ¨¡å¼...")
        for path, file_info in file_infos:
            try:
                text_input = parse_word_to_text_input(path)
                file_root = output_root if output_root else (path.parent / "review_results")
                file_output_dir = file_root / path.stem
                file_output_dir.mkdir(parents=True, exist_ok=True)
                
                # ä¿å­˜æœ¬åœ°è§£æç»“æœ
                analysis_data = {
                    "fileName": file_info.get("fileName"),
                    "fileUrl": file_info.get("fileUrl"),
                    "savedAt": datetime.now().isoformat(),
                    "parseMode": "local",
                    "textInput": text_input
                }
                analysis_path = file_output_dir / "analysis.json"
                analysis_path.write_text(json.dumps(analysis_data, ensure_ascii=False, indent=2), encoding="utf-8")
                print(f"âœ… æœ¬åœ°è§£æå®Œæˆ: {file_info.get('fileName')}")
                prepared_files.append((path, file_info, text_input, file_output_dir))
            except Exception as e:
                print(f"âŒ æœ¬åœ°è§£æå¤±è´¥: {file_info.get('fileName')} ({e})")
    else:
        # äº‘ç«¯è§£ææ¨¡å¼ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        max_parse_retries = 3
        parse_retry_delay = 2  # é‡è¯•é—´éš”ç§’æ•°
        
        for path, file_info in file_infos:
            success = False
            text_input = None
            analysis_result = None
            
            for retry in range(max_parse_retries):
                if retry > 0:
                    print(f"ğŸ”„ é‡è¯•è§£æ ({retry}/{max_parse_retries-1}): {file_info.get('fileName')}")
                    await asyncio.sleep(parse_retry_delay)
                
                success, analysis_result, text_input = await async_homework_analysis(file_info, context, semaphore)
                
                if success and text_input:
                    break
            
            if not success or not text_input:
                reason = "è§£æå¤±è´¥"
                if isinstance(analysis_result, dict):
                    reason = analysis_result.get("msg") or analysis_result.get("error") or reason
                print(f"âŒ è§£æå¤±è´¥ (å·²é‡è¯•{max_parse_retries-1}æ¬¡): {file_info.get('fileName')} ({reason})")
                continue

            file_root = output_root if output_root else (path.parent / "review_results")
            file_output_dir = file_root / path.stem
            file_output_dir.mkdir(parents=True, exist_ok=True)
            analysis_path = save_analysis_result(file_output_dir, file_info, analysis_result, text_input)
            print(f"âœ… è§£æå®Œæˆ: {file_info.get('fileName')} -> {analysis_path}")

            # LLM æ ¡éªŒè¡¥å……ç©ºç™½ç­”æ¡ˆ
            if LLM_CORRECTOR_AVAILABLE:
                try:
                    text_input = await async_correct_answers_with_llm(path, text_input)
                except Exception as e:
                    print(f"âš ï¸ LLM æ ¡éªŒå¤±è´¥: {e}ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹è§£æç»“æœ")

            prepared_files.append((path, file_info, text_input, file_output_dir))

    if not prepared_files:
        print("\nâŒ æ²¡æœ‰æˆåŠŸè§£æçš„æ–‡ä»¶ï¼Œæ— æ³•æ‰§è¡Œæ‰¹æ”¹")
        return

    tasks = []
    for path, file_info, text_input, file_output_dir in prepared_files:
        for attempt_index in range(1, attempts + 1):
            tasks.append(
                evaluate_and_save(
                    path,
                    file_info,
                    text_input,
                    context,
                    file_output_dir,
                    attempt_index,
                    attempts,
                    output_format,
                    semaphore
                )
            )

    results = await asyncio.gather(*tasks)
    success_count = sum(1 for item in results if item and item.get("success"))
    print(f"\nâœ… å·²å®Œæˆ {len(results)} æ¬¡æµ‹è¯„ï¼ˆæˆåŠŸ {success_count}ï¼‰")
    generate_excel_summary(results, [item[0] for item in prepared_files], attempts, output_root)

    return {
        "results": results,
        "prepared_files": [str(item[0]) for item in prepared_files],
        "output_root": str(output_root) if output_root else None,
        "attempts": attempts,
        "output_format": output_format,
        "success_count": success_count,
    }


def main():
    """ä¸»å‡½æ•°ï¼šå¤„ç†ç”¨æˆ·äº¤äº’å’Œæ–‡ä»¶ä¸Šä¼ """
    print("=" * 60)
    print("ä½œä¸šæ‰¹æ”¹ç³»ç»Ÿ - v2 (ä¸Šä¼  -> è§£æ -> æ‰¹æ”¹)")
    print("=" * 60)

    # åŠ è½½ç¯å¢ƒé…ç½®
    try:
        load_env_config()
    except FileNotFoundError as e:
        print(f"\nâŒ {e}")
        return

    # è‡ªåŠ¨è·å–å®ä¾‹ä¿¡æ¯ï¼ˆä¸å†™å›.envï¼‰
    context = ensure_instance_context()
    if not context:
        return

    instance_name = (context.get("instance_name") or "").strip()
    desc = (context.get("desc") or "").strip()
    if instance_name or desc:
        print("\nğŸ“Œ ä½œä¸šä¿¡æ¯ï¼š")
        if instance_name:
            print(f"åç§°: {instance_name}")
        if desc:
            print(f"æè¿°: {desc}")

    # é€‰æ‹©ä¸Šä¼ æ–¹å¼
    print("\nè¯·é€‰æ‹©ä¸Šä¼ æ–¹å¼ï¼š")
    print("1) å•ä¸ª/å¤šä¸ªæ–‡ä»¶")
    print("2) æ–‡ä»¶å¤¹")
    upload_choice = input("è¯·è¾“å…¥é€‰é¡¹ (1/2ï¼Œé»˜è®¤2): ").strip()

    file_paths = []
    output_root = None

    if upload_choice == "" or upload_choice == "2":
        folder_input = input("è¯·è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„: ").strip()
        if not folder_input:
            print("âŒ æœªè¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„")
            return
        folder_path = normalize_input_path(folder_input)
        file_paths = collect_files_from_folder(folder_path)
        if not file_paths:
            print("âŒ æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°å¯ä¸Šä¼ çš„æ–‡ä»¶")
            return
        output_root = folder_path / "review_results"
    else:
        print("\nè¯·è¾“å…¥è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„ï¼ˆå¤šä¸ªæ–‡ä»¶ç”¨é€—å·åˆ†éš”ï¼‰ï¼š")
        print("ç¤ºä¾‹: /path/to/file1.png,/path/to/file2.jpeg")
        file_paths_input = input("æ–‡ä»¶è·¯å¾„: ").strip()
        if not file_paths_input:
            print("âŒ æœªè¾“å…¥æ–‡ä»¶è·¯å¾„")
            return
        file_paths = [normalize_input_path(path.strip()) for path in file_paths_input.split(',') if path.strip()]
        if not file_paths:
            print("âŒ æœªè¾“å…¥æœ‰æ•ˆæ–‡ä»¶è·¯å¾„")
            return
        output_root = None

    # è¯¢é—®æµ‹è¯„æ¬¡æ•°
    attempts_input = input("æ¯ä¸ªæ–‡æ¡£éœ€è¦æµ‹è¯„å‡ æ¬¡ï¼Ÿ(é»˜è®¤5): ").strip()
    attempts = 5
    if attempts_input:
        try:
            attempts = int(attempts_input)
        except ValueError:
            print("âŒ æµ‹è¯„æ¬¡æ•°å¿…é¡»ä¸ºæ•´æ•°")
            return
        if attempts <= 0:
            print("âŒ æµ‹è¯„æ¬¡æ•°å¿…é¡»å¤§äº0")
            return

    print("\nè¯·é€‰æ‹©æŠ¥å‘Šæ ¼å¼ï¼š")
    print("1) JSON æŠ¥å‘Šï¼ˆé»˜è®¤,ç”Ÿæˆé€Ÿåº¦å¿«ï¼‰")
    print("2) PDF æŠ¥å‘Šï¼ˆéœ€è¦å®Œæ•´è¯„åˆ†ç»“æœï¼‰")
    report_choice = input("è¯·è¾“å…¥é€‰é¡¹ (1/2): ").strip().lower()
    output_format = "pdf" if report_choice in {"2", "pdf"} else "json"

    # è¯¢é—®è§£ææ¨¡å¼
    local_parse = False
    if LOCAL_PARSER_AVAILABLE:
        print("\nè¯·é€‰æ‹©è§£ææ¨¡å¼ï¼š")
        print("1) äº‘ç«¯è§£æï¼ˆé»˜è®¤ï¼Œä½¿ç”¨æ™ºæ…§æ ‘ APIï¼‰")
        print("2) æœ¬åœ°è§£æï¼ˆè·³è¿‡äº‘ç«¯ APIï¼Œè§£ææ›´ç¨³å®šï¼‰")
        parse_choice = input("è¯·è¾“å…¥é€‰é¡¹ (1/2): ").strip()
        local_parse = parse_choice == "2"

    print(f"\nğŸ“‚ å…±éœ€è¦ä¸Šä¼  {len(file_paths)} ä¸ªæ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶æµ‹è¯„ {attempts} æ¬¡")
    print(f"   è¾“å‡ºæ ¼å¼: {output_format}ï¼Œè§£ææ¨¡å¼: {'æœ¬åœ°' if local_parse else 'äº‘ç«¯'}\n")

    asyncio.run(run_batch(file_paths, attempts, context, output_root, output_format, local_parse=local_parse))


if __name__ == "__main__":
    main()
