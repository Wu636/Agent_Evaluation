"""
LLM ç­”æ¡ˆæ ¡éªŒæ¨¡å—
ç”¨äºŽæ ¡éªŒå’Œè¡¥å……äº‘ç«¯ OCR è§£æžä¸­ç©ºç™½æˆ–é”™è¯¯çš„ç­”æ¡ˆ
"""

import json
import os
import re
from pathlib import Path
from typing import List, Dict, Tuple, Optional

import requests
from dotenv import load_dotenv

try:
    from docx import Document
except ImportError:
    Document = None


def load_llm_config() -> Tuple[str, str]:
    """åŠ è½½ LLM API é…ç½®"""
    load_dotenv()
    api_key = os.getenv("LLM_API_KEY", "")
    api_url = os.getenv("LLM_API_URL", "http://llm-service.polymas.com/api/openai/v1/chat/completions")
    return api_key, api_url


def extract_text_from_docx(docx_path: Path) -> str:
    """ä»Ž Word æ–‡æ¡£æå–çº¯æ–‡æœ¬"""
    if Document is None:
        raise ImportError("è¯·å®‰è£… python-docx: pip install python-docx")
    
    doc = Document(docx_path)
    paragraphs = [p.text.strip() for p in doc.paragraphs if p.text.strip()]
    return "\n".join(paragraphs)


def find_answer_issues(items: List[Dict]) -> List[Dict]:
    """
    æ£€æµ‹ç­”æ¡ˆä¸­çš„é—®é¢˜
    è¿”å›žéœ€è¦è¡¥å……çš„é¢˜ç›®åˆ—è¡¨
    """
    issues = []
    
    for i, item in enumerate(items):
        item_name = item.get("itemName", "")
        answer = item.get("stuAnswerContent", "")
        
        # æ£€æµ‹ç©ºç™½ç­”æ¡ˆ
        if not answer or answer.strip() == "":
            issues.append({
                "index": i,
                "itemName": item_name,
                "issue": "ç­”æ¡ˆä¸ºç©º",
                "current": answer
            })
            continue
        
        # æ£€æµ‹é€‰æ‹©é¢˜ç­”æ¡ˆæ ¼å¼é—®é¢˜
        if "é€‰æ‹©é¢˜" in item_name:
            # é€‰æ‹©é¢˜ç­”æ¡ˆåº”è¯¥æ˜¯ A/B/C/D
            if not re.match(r'^[A-Da-d]$', answer.strip()):
                issues.append({
                    "index": i,
                    "itemName": item_name,
                    "issue": "é€‰æ‹©é¢˜ç­”æ¡ˆæ ¼å¼å¼‚å¸¸",
                    "current": answer[:50] if len(answer) > 50 else answer
                })
        
        # æ£€æµ‹åˆ¤æ–­é¢˜ç­”æ¡ˆæ ¼å¼é—®é¢˜
        elif "åˆ¤æ–­é¢˜" in item_name:
            # åˆ¤æ–­é¢˜ç­”æ¡ˆåº”è¯¥æ˜¯ âˆš/Ã—/å¯¹/é”™/T/F ç­‰
            valid_answers = ["âˆš", "Ã—", "âœ“", "âœ—", "å¯¹", "é”™", "æ˜¯", "å¦", "T", "F", "t", "f"]
            if answer.strip() not in valid_answers:
                issues.append({
                    "index": i,
                    "itemName": item_name,
                    "issue": "åˆ¤æ–­é¢˜ç­”æ¡ˆæ ¼å¼å¼‚å¸¸",
                    "current": answer[:50] if len(answer) > 50 else answer
                })
    
    return issues


def build_correction_prompt(doc_text: str, items: List[Dict], issues: List[Dict]) -> str:
    """æž„å»º LLM æ ¡éªŒçš„ prompt"""
    
    # æž„å»ºé—®é¢˜åˆ—è¡¨æè¿°
    issues_desc = []
    for issue in issues:
        issues_desc.append(f"- {issue['itemName']}: {issue['issue']}ï¼Œå½“å‰å€¼=\"{issue['current']}\"")
    
    # æž„å»ºå½“å‰è§£æžç»“æžœæ‘˜è¦
    items_summary = []
    for item in items:
        name = item.get("itemName", "")
        answer = item.get("stuAnswerContent", "")
        preview = answer[:30].replace("\n", " ") if answer else "(ç©º)"
        items_summary.append(f"  {name}: {preview}")
    
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä½œä¸šç­”æ¡ˆæ ¡éªŒåŠ©æ‰‹ã€‚è¯·å¯¹æ¯”ã€åŽŸå§‹æ–‡æ¡£å†…å®¹ã€‘å’Œã€OCRè§£æžç»“æžœã€‘ï¼Œæ‰¾å‡ºå¹¶è¡¥å……ç¼ºå¤±æˆ–é”™è¯¯çš„ç­”æ¡ˆã€‚

ã€åŽŸå§‹æ–‡æ¡£å†…å®¹ã€‘
{doc_text[:8000]}

ã€OCRè§£æžç»“æžœæ‘˜è¦ã€‘
{chr(10).join(items_summary[:30])}

ã€éœ€è¦æ ¡éªŒè¡¥å……çš„é¢˜ç›®ã€‘
{chr(10).join(issues_desc)}

è¯·ä»”ç»†é˜…è¯»åŽŸå§‹æ–‡æ¡£ï¼Œæ‰¾å‡ºä¸Šè¿°é¢˜ç›®çš„æ­£ç¡®ç­”æ¡ˆã€‚

è¾“å‡ºè¦æ±‚ï¼š
1. ç›´æŽ¥è¾“å‡º JSON æ ¼å¼ï¼ŒåŒ…å«éœ€è¦ä¿®æ­£çš„é¢˜ç›®
2. æ ¼å¼ä¸º: {{"corrections": [{{"itemName": "é¢˜ç›®åç§°", "stuAnswerContent": "æ­£ç¡®ç­”æ¡ˆ"}}]}}
3. é€‰æ‹©é¢˜åªè¾“å‡ºé€‰é¡¹å­—æ¯ï¼ˆå¦‚ A/B/C/Dï¼‰
4. åˆ¤æ–­é¢˜è¾“å‡º âˆš æˆ– Ã—
5. ä¸»è§‚é¢˜è¾“å‡ºå®Œæ•´ç­”æ¡ˆå†…å®¹
6. åªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–è§£é‡Š

è¯·å¼€å§‹ï¼š"""
    
    return prompt


def call_llm_api(prompt: str, api_key: str, api_url: str) -> Optional[str]:
    """è°ƒç”¨ LLM API"""
    headers = {
        "api-key": api_key,
        "Content-Type": "application/json"
    }
    
    payload = {
        "maxTokens": 4096,
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä½œä¸šç­”æ¡ˆæ ¡éªŒåŠ©æ‰‹ï¼Œæ“…é•¿ä»Žæ–‡æ¡£ä¸­æå–å’Œè¡¥å……ç­”æ¡ˆã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "model": "claude-sonnet-4-20250514",  # Claude Sonnet 4.5
        "temperature": 0.1,  # ä½Žæ¸©åº¦ç¡®ä¿è¾“å‡ºç¨³å®š
        "n": 1
    }
    
    try:
        response = requests.post(api_url, headers=headers, json=payload, timeout=120)
        response.raise_for_status()
        result = response.json()
        
        if "choices" in result and len(result["choices"]) > 0:
            return result["choices"][0]["message"]["content"]
        return None
    except Exception as e:
        print(f"âŒ LLM API è°ƒç”¨å¤±è´¥: {e}")
        return None


def parse_llm_response(response: str) -> List[Dict]:
    """è§£æž LLM è¿”å›žçš„ä¿®æ­£ç»“æžœ"""
    if not response:
        return []
    
    try:
        # å°è¯•æå– JSON
        json_match = re.search(r'\{[\s\S]*\}', response)
        if json_match:
            data = json.loads(json_match.group())
            return data.get("corrections", [])
    except json.JSONDecodeError:
        pass
    
    return []


def apply_corrections(items: List[Dict], corrections: List[Dict]) -> List[Dict]:
    """å°†ä¿®æ­£ç»“æžœåº”ç”¨åˆ°åŽŸå§‹æ•°æ®"""
    # åˆ›å»º itemName -> correction æ˜ å°„
    correction_map = {}
    for corr in corrections:
        name = corr.get("itemName", "")
        if name:
            correction_map[name] = corr.get("stuAnswerContent", "")
    
    # åº”ç”¨ä¿®æ­£
    corrected_count = 0
    for item in items:
        item_name = item.get("itemName", "")
        if item_name in correction_map:
            old_value = item.get("stuAnswerContent", "")
            new_value = correction_map[item_name]
            if new_value and new_value != old_value:
                item["stuAnswerContent"] = new_value
                corrected_count += 1
                print(f"  âœï¸ ä¿®æ­£ {item_name}: \"{old_value[:20]}...\" â†’ \"{new_value[:50]}...\"")
    
    return items


def correct_answers_with_llm(docx_path: Path, text_input: str) -> str:
    """
    ä½¿ç”¨ LLM æ ¡éªŒå¹¶è¡¥å……ç©ºç™½ç­”æ¡ˆ
    
    Args:
        docx_path: åŽŸå§‹ Word æ–‡æ¡£è·¯å¾„
        text_input: äº‘ç«¯ OCR è§£æžçš„ textInput JSON å­—ç¬¦ä¸²
        
    Returns:
        ä¿®æ­£åŽçš„ textInput JSON å­—ç¬¦ä¸²
    """
    # åŠ è½½é…ç½®
    api_key, api_url = load_llm_config()
    if not api_key:
        print("âš ï¸ æœªé…ç½® LLM_API_KEYï¼Œè·³è¿‡ LLM æ ¡éªŒ")
        return text_input
    
    # è§£æž textInput
    try:
        items = json.loads(text_input)
    except json.JSONDecodeError:
        print("âš ï¸ textInput æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡ LLM æ ¡éªŒ")
        return text_input
    
    # æ£€æµ‹é—®é¢˜
    issues = find_answer_issues(items)
    if not issues:
        print("âœ… æ‰€æœ‰ç­”æ¡ˆæ ¼å¼æ­£å¸¸ï¼Œæ— éœ€ LLM æ ¡éªŒ")
        return text_input
    
    print(f"\nðŸ” æ£€æµ‹åˆ° {len(issues)} ä¸ªé—®é¢˜ç­”æ¡ˆï¼Œå¯åŠ¨ LLM æ ¡éªŒ...")
    for issue in issues[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"  - {issue['itemName']}: {issue['issue']}")
    if len(issues) > 5:
        print(f"  ... è¿˜æœ‰ {len(issues) - 5} ä¸ªé—®é¢˜")
    
    # æå–æ–‡æ¡£æ–‡æœ¬
    try:
        doc_text = extract_text_from_docx(docx_path)
    except Exception as e:
        print(f"âš ï¸ æ–‡æ¡£è¯»å–å¤±è´¥: {e}ï¼Œè·³è¿‡ LLM æ ¡éªŒ")
        return text_input
    
    # æž„å»º prompt å¹¶è°ƒç”¨ LLM
    prompt = build_correction_prompt(doc_text, items, issues)
    print("ðŸ¤– è°ƒç”¨ LLM æ ¡éªŒä¸­...")
    
    llm_response = call_llm_api(prompt, api_key, api_url)
    if not llm_response:
        print("âš ï¸ LLM æœªè¿”å›žç»“æžœï¼Œè·³è¿‡æ ¡éªŒ")
        return text_input
    
    # è§£æžä¿®æ­£ç»“æžœ
    corrections = parse_llm_response(llm_response)
    if not corrections:
        print("âš ï¸ LLM æœªè¿”å›žæœ‰æ•ˆä¿®æ­£ï¼Œè·³è¿‡æ ¡éªŒ")
        return text_input
    
    # åº”ç”¨ä¿®æ­£
    print(f"\nðŸ“ åº”ç”¨ {len(corrections)} ä¸ªä¿®æ­£...")
    corrected_items = apply_corrections(items, corrections)
    
    print("âœ… LLM æ ¡éªŒå®Œæˆ")
    return json.dumps(corrected_items, ensure_ascii=False)


# å¼‚æ­¥ç‰ˆæœ¬
async def async_correct_answers_with_llm(docx_path: Path, text_input: str) -> str:
    """å¼‚æ­¥ç‰ˆæœ¬çš„ LLM æ ¡éªŒ"""
    import asyncio
    # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥ç‰ˆæœ¬
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, correct_answers_with_llm, docx_path, text_input)


if __name__ == "__main__":
    # æµ‹è¯•ç”¨
    import sys
    
    if len(sys.argv) > 2:
        docx_path = Path(sys.argv[1])
        text_input = sys.argv[2]
        
        result = correct_answers_with_llm(docx_path, text_input)
        print("\nä¿®æ­£åŽçš„ textInput:")
        print(result[:500] + "..." if len(result) > 500 else result)
    else:
        print("ç”¨æ³•: python llm_answer_corrector.py <docxè·¯å¾„> <textInput>")
