# 🚀 LLM评测系统 - 快速开始

## 📋 准备工作检查清单

在开始之前,请确认:
- [ ] Python 3.8+ 已安装
- [ ] 有可用的LLM API (地址和密钥)
- [ ] 已准备教师文档(.docx或.md格式)
- [ ] 已准备对话记录(.json格式)

## 🎯 5分钟快速上手

### Step 1: 安装依赖

```bash
# 进入项目目录
cd /你的/项目/目录

# 安装必需的库
pip install requests --break-system-packages
```

### Step 2: 配置API

**使用配置向导(最简单):**

```bash
python setup_config.py
```

会出现交互式界面:
```
======================================================================
  LLM评测系统配置向导
======================================================================

请按提示输入配置信息:

1️⃣  请输入你的 API Key:
   (示例: sk-abc123xyz789)
   API_KEY: ▮

2️⃣  请输入 API 地址:
   (默认: http://llm-service.polymas.com/api/openai/v1/chat/completions)
   API_URL [回车使用默认]: ▮

3️⃣  请输入使用的模型:
   (默认: gpt-4o)
   MODEL [回车使用默认]: ▮

======================================================================
  配置预览
======================================================================
API_KEY: sk-abc123...xyz789
API_URL: http://llm-service.polymas.com/api/openai/v1/chat/completions
MODEL:   gpt-4o
======================================================================

确认保存? (y/n): y

✅ 配置文件已保存至: .env
```

### Step 3: 测试连接

**在配置向导中选择测试:**
```
请选择操作:
  1. 配置API设置(创建.env文件)
  2. 测试API连接  ← 选择这个
  3. 查看当前配置
  0. 退出

请输入选项 (0-3): 2

======================================================================
  测试API连接
======================================================================
API地址: http://llm-service.polymas.com/api/openai/v1/chat/completions
模型: gpt-4o

正在发送测试请求...

✅ 连接成功!
   模型回复: 连接成功
   Token使用: 25

配置正确,可以开始使用评测系统!
```

### Step 4: 运行第一次评测

```bash
python llm_evaluation_agent.py 教师文档.docx 对话记录.json
```

**运行过程:**
```
✓ 找到配置文件: .env
✓ 已加载教师文档: 8234 字符
✓ 已加载对话记录: 14 轮
✓ LLM配置: http://llm-service.polymas.com/... / gpt-4o

======================================================================
开始LLM驱动的智能体评测
======================================================================

⏳ 正在评测: 教学目标与任务完成度...
   Token使用: 提示5234 + 生成823 = 总计6057
✓ 教学目标与任务完成度: 85.0分 - 良好

⏳ 正在评测: 教学策略与引导质量...
   Token使用: 提示4532 + 生成756 = 总计5288
✓ 教学策略与引导质量: 78.0分 - 良好

⏳ 正在评测: 对话流程一致性与工作流遵循度...
   Token使用: 提示4123 + 生成634 = 总计4757
✓ 对话流程一致性与工作流遵循度: 92.0分 - 优秀

⏳ 正在评测: 语言与交互体验...
   Token使用: 提示3856 + 生成512 = 总计4368
✓ 语言与交互体验: 82.0分 - 良好

⏳ 正在评测: 幻觉与不当输出控制...
   Token使用: 提示4321 + 生成687 = 总计5008
✓ 幻觉与不当输出控制: 68.0分 - 合格

⏳ 正在评测: 鲁棒性与异常处理能力...
   Token使用: 提示3245 + 生成445 = 总计3690
✓ 鲁棒性与异常处理能力: 72.0分 - 合格

======================================================================
评测完成!总分: 81.4 - 良好
======================================================================

✓ 报告已保存: dialogue_xxx_llm_evaluation.txt
```

### Step 5: 查看报告

```bash
# 用文本编辑器打开报告
cat dialogue_xxx_llm_evaluation.txt

# 或用你喜欢的编辑器
code dialogue_xxx_llm_evaluation.txt  # VS Code
open dialogue_xxx_llm_evaluation.txt  # macOS
```

**报告结构:**
```
================================================================================
基于LLM的实训智能体评测报告
================================================================================

任务ID: WwD67NJv2GsyEeBYGxkJ
评测时间: 2025-12-18 11:32:46
学生类型: 优秀学生
对话轮次: 14

================================================================================
## 评测结论: 良好 (81.4/100)

### 各维度得分
✅ **教学目标与任务完成度**: 34.0/40 (原始85.0/100 - 良好)
✅ **教学策略与引导质量**: 15.6/20 (原始78.0/100 - 良好)
✅ **对话流程一致性与工作流遵循度**: 13.8/15 (原始92.0/100 - 优秀)
✅ **语言与交互体验**: 8.2/10 (原始82.0/100 - 良好)
⚠️ **幻觉与不当输出控制**: 6.8/10 (原始68.0/100 - 合格)
⚠️ **鲁棒性与异常处理能力**: 3.6/5 (原始72.0/100 - 合格)

### 核心发现
- ✨ **优势**: 对话流程一致性与工作流遵循度表现最好(92.0分)
- 🔧 **待改进**: 幻觉与不当输出控制需要重点优化(68.0分)

================================================================================
详细分析
================================================================================

### 教学目标与任务完成度
**得分**: 34.0/40 (原始85.0/100)
**等级**: 良好

**分析**:
智能体完成了文档中规定的5个主要环节,覆盖了核心知识点和操作步骤...

**支撑证据**:
  ✓ 环节1'母株选择'中,完整传达了3-5年生、直径1.0-1.5cm等关键参数
  ✓ 环节2'环剥操作'中,准确说明了深度至木质部、宽度1.5倍等标准
  ...

**发现的问题**:
  ✗ 遗漏了'雨天检查透气孔'这一养护要点
  ✗ 第三环节'基质包裹'中,未明确提及透气孔的具体位置要求
  ...

**改进建议**:
  → 补充完整的养护注意事项清单
  → 在基质包裹环节增加透气孔位置的详细说明
  ...

[... 其他维度的详细分析 ...]
```

## 🎓 理解评测结果

### 阅读优先级

1. **先看总分和等级** - 快速了解整体水平
2. **查看核心发现** - 知道优势和短板
3. **关注低分维度** - 重点改进的方向
4. **阅读具体问题** - 明确要修改什么
5. **参考改进建议** - 知道怎么改

### 分数含义

| 分数范围 | 等级 | 说明 | 行动建议 |
|---------|------|------|---------|
| 90-100 | 优秀 | 表现出色 | 可投入生产,持续优化 |
| 75-89 | 良好 | 基本满意 | 针对性改进低分项 |
| 60-74 | 合格 | 勉强达标 | 需要系统性优化 |
| <60 | 不合格 | 问题较多 | 重新设计或大幅调整 |
| 一票否决 | 不合格 | 核心任务未完成 | 必须解决后才能使用 |

### 关键指标解读

**教学目标完成度 < 60分:**
- 🚨 这是一票否决项!
- 意味着核心教学任务没完成
- 即使其他维度满分也不能通过

**幻觉控制分数低:**
- ⚠️ 可能编造了不存在的内容
- 或参数与文档不一致
- 需要严格对照文档修正

**教学策略分数低:**
- 💡 可能直接给答案,缺少引导
- 需要改为苏格拉底式提问
- 让学生思考而非灌输

## 💡 常见问题

### Q1: 配置文件放哪里?

.env文件应该和llm_evaluation_agent.py在同一目录:
```
your-project/
  ├── llm_evaluation_agent.py
  ├── .env                    ← 这里
  ├── setup_config.py
  └── ...
```

### Q2: 能否用其他LLM模型?

可以!编辑.env文件:
```bash
# 使用GPT-3.5(更便宜)
LLM_MODEL=gpt-3.5-turbo

# 使用GPT-4(更准确)
LLM_MODEL=gpt-4

# 使用GPT-4o(推荐,性价比高)
LLM_MODEL=gpt-4o
```

### Q3: API调用失败怎么办?

运行测试连接:
```bash
python setup_config.py
# 选择 "2. 测试API连接"
```

根据错误提示:
- HTTP 401: API Key错误
- HTTP 404: URL地址错误
- Connection Error: 网络问题或URL错误
- Timeout: 网络超时

### Q4: 评测要多久?

取决于:
- 对话长度: 14轮约2-3分钟
- 模型速度: GPT-4o较快,GPT-4较慢
- 网络状况: 国内可能较慢

**典型耗时:**
- 短对话(10轮): 1-2分钟
- 中等对话(20轮): 3-5分钟
- 长对话(50轮): 8-15分钟

### Q5: 成本多少?

使用你们的API,具体询问管理员。

参考OpenAI官方定价:
- GPT-4o: ~$1-2/次评测
- GPT-3.5: ~$0.10-0.20/次

## 🎯 下一步

现在你已经完成了第一次评测!接下来:

1. **理解报告** - 仔细阅读各维度分析
2. **定位问题** - 找出得分最低的维度
3. **制定计划** - 根据建议制定优化方案
4. **修改智能体** - 调整提示词或流程
5. **重新评测** - 验证改进效果
6. **持续迭代** - 直到达到目标分数

## 📞 获取帮助

遇到问题?
1. 查看 `LLM_EVALUATION_GUIDE.md` 详细文档
2. 运行 `python setup_config.py` 检查配置
3. 查看错误信息,对照故障排查指南

祝你评测顺利! 🎉
