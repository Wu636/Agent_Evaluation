# 常见问题排查指南

## 🚀 流式响应已启用

**好消息**：系统已升级为流式响应模式，理论上不再受 Vercel 60 秒超时限制。

只要 LLM 持续输出 token，Vercel 就会持续重置超时计时器。

---

## 常见问题

### 1. 评测结果显示"解析失败"

**原因**：LLM 返回的内容不是有效的 JSON 格式。

**解决方案**：
- 系统已集成 `jsonrepair` 自动修复，大部分情况可自动处理
- 如果频繁出现，尝试切换模型（推荐 GPT-4o）

---

### 2. 评测时间很长（超过 5 分钟）

**原因**：LLM 响应速度慢，需要评测 21 个子维度。

**解决方案**：
- 使用更快的模型（GPT-4o-mini 最快）
- 系统使用 5 路并发，已是最优配置

---

### 3. 部分子维度评测失败

**原因**：个别 API 请求失败（网络波动、服务端繁忙）。

**解决方案**：
- 系统已内置自动重试机制（最多 2 次）
- 失败的维度会显示"解析失败"，但不影响其他维度

---

### 4. 报错 "网络错误" 或 "fetch failed"

**可能原因**：
1. API 密钥无效
2. API 地址错误
3. 网络连接问题

**解决方案**：
1. 检查"设置"中的 API 配置
2. 确认 API 地址格式正确（如：`https://api.openai.com/v1/chat/completions`）
3. 检查网络连接

---

### 5. 上传文件后无反应

**可能原因**：文件格式不支持。

**支持的格式**：
- 教师文档：`.doc`、`.docx`、`.md`
- 对话记录：`.json`、`.txt`

---

## 各模型响应时间参考

| 模型 | 单维度耗时 | 21维度总耗时 | 推荐度 |
|------|-----------|-------------|--------|
| Claude Sonnet | 30-60秒 | 3-5 分钟 | ⭐⭐⭐⭐⭐ 推荐 报告详细准确 |
| GPT-4o | 15-30秒 | 1-3分钟 | ⭐⭐⭐ 推荐 |
| GPT-4o-mini | 8-15秒 | 1分钟内 | ⭐⭐ 推荐 |



---

## 本地运行（无任何限制）

如果您有特殊需求或遇到部署问题，可以本地运行：

```bash
cd frontend
npm install
npm run dev
```

访问 `http://localhost:3000`

本地运行没有任何超时限制，适合长时间评测。

---

## 联系支持

如问题仍未解决，请提供以下信息：
1. 浏览器控制台错误截图
2. 终端日志（如有）
3. 使用的模型名称

---

**最后更新**: 2026-01-09
