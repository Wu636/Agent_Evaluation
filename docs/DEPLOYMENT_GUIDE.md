# LLM è¯„æµ‹ç³»ç»Ÿéƒ¨ç½²æŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»å¦‚ä½•å°† Agent_Evaluation é¡¹ç›®éƒ¨ç½²åˆ°ç”Ÿäº§çŽ¯å¢ƒã€‚

---

## ðŸ“‹ éƒ¨ç½²å‰å‡†å¤‡

### å¿…éœ€é¡¹
- GitHub è´¦å·ï¼ˆå·²æœ‰ä»“åº“ï¼š[Wu636/Agent_Evaluation](https://github.com/Wu636/Agent_Evaluation)ï¼‰
- LLM API å¯†é’¥

### é¡¹ç›®ç»“æž„
```
Agent_Evaluation/
â”œâ”€â”€ frontend/          # Next.js å‰ç«¯
â”œâ”€â”€ backend/           # FastAPI åŽç«¯
â”œâ”€â”€ docs/              # æ–‡æ¡£
â””â”€â”€ scripts/           # å·¥å…·è„šæœ¬
```

---

## ðŸš€ æ–¹æ¡ˆä¸€ï¼šVercel + Railwayï¼ˆæŽ¨èï¼‰

### ä¼˜åŠ¿
- âœ… é›¶é…ç½®éƒ¨ç½²ï¼Œè¿žæŽ¥ GitHub å³å¯
- âœ… è‡ªåŠ¨ CI/CDï¼ŒæŽ¨é€ä»£ç è‡ªåŠ¨é‡æ–°éƒ¨ç½²
- âœ… å…è´¹é¢åº¦å……è¶³
- âœ… å…¨çƒ CDN åŠ é€Ÿ

---

### æ­¥éª¤ 1ï¼šéƒ¨ç½²å‰ç«¯åˆ° Vercel

#### 1.1 ç™»å½• Vercel
1. è®¿é—® https://vercel.com
2. ç‚¹å‡» "Sign Up" æˆ– "Log In"
3. é€‰æ‹© "Continue with GitHub"

#### 1.2 å¯¼å…¥é¡¹ç›®
1. ç‚¹å‡» "Add New..." â†’ "Project"
2. åœ¨ "Import Git Repository" ä¸­æ‰¾åˆ° `Wu636/Agent_Evaluation`
3. ç‚¹å‡» "Import"

#### 1.3 é…ç½®é¡¹ç›®
| é…ç½®é¡¹ | å€¼ |
|--------|-----|
| **Project Name** | agent-evaluationï¼ˆæˆ–è‡ªå®šä¹‰ï¼‰|
| **Framework Preset** | Next.jsï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰ |
| **Root Directory** | `frontend` |
| **Build Command** | `npm run build`ï¼ˆé»˜è®¤ï¼‰ |
| **Output Directory** | `.next`ï¼ˆé»˜è®¤ï¼‰ |

#### 1.4 é…ç½®çŽ¯å¢ƒå˜é‡
åœ¨ "Environment Variables" ä¸­æ·»åŠ ï¼š

| Key | Value | è¯´æ˜Ž |
|-----|-------|------|
| `NEXT_PUBLIC_API_URL` | `https://ä½ çš„RailwayåŽç«¯URL` | åŽç«¯ API åœ°å€ï¼Œç¨åŽé…ç½® |

> âš ï¸ å…ˆè·³è¿‡çŽ¯å¢ƒå˜é‡ï¼Œéƒ¨ç½²åŽç«¯åŽå†å›žæ¥æ›´æ–°

#### 1.5 éƒ¨ç½²
ç‚¹å‡» "Deploy" æŒ‰é’®ï¼Œç­‰å¾… 2-3 åˆ†é’Ÿå®Œæˆéƒ¨ç½²ã€‚

éƒ¨ç½²æˆåŠŸåŽä¼šèŽ·å¾—ä¸€ä¸ª URLï¼Œå¦‚ï¼š`https://agent-evaluation.vercel.app`

---

### æ­¥éª¤ 2ï¼šéƒ¨ç½²åŽç«¯åˆ° Railway

#### 2.1 ç™»å½• Railway
1. è®¿é—® https://railway.app
2. ç‚¹å‡» "Login" â†’ "Login with GitHub"

#### 2.2 åˆ›å»ºé¡¹ç›®
1. ç‚¹å‡» "New Project"
2. é€‰æ‹© "Deploy from GitHub repo"
3. é€‰æ‹© `Wu636/Agent_Evaluation` ä»“åº“

#### 2.3 é…ç½®æœåŠ¡
åœ¨é¡¹ç›®è®¾ç½®ä¸­é…ç½®ï¼š

| é…ç½®é¡¹ | å€¼ |
|--------|-----|
| **Root Directory** | `backend` |
| **Start Command** | `uvicorn main:app --host 0.0.0.0 --port $PORT` |

#### 2.4 é…ç½®çŽ¯å¢ƒå˜é‡
åœ¨ "Variables" ä¸­æ·»åŠ ï¼š

| Key | Value |
|-----|-------|
| `LLM_API_KEY` | ä½ çš„ LLM API å¯†é’¥ |
| `LLM_BASE_URL` | `http://llm-service.polymas.com/api/openai/v1/chat/completions` |
| `LLM_MODEL` | `gpt-4o` |

#### 2.5 ç”Ÿæˆå…¬å¼€ URL
1. è¿›å…¥ "Settings" â†’ "Networking"
2. ç‚¹å‡» "Generate Domain"
3. èŽ·å¾— URLï¼Œå¦‚ï¼š`https://agent-evaluation-backend.railway.app`

#### 2.6 æ›´æ–°å‰ç«¯çŽ¯å¢ƒå˜é‡
å›žåˆ° Vercel é¡¹ç›®ï¼š
1. è¿›å…¥ "Settings" â†’ "Environment Variables"
2. æ›´æ–° `NEXT_PUBLIC_API_URL` ä¸º Railway åŽç«¯ URL
3. é‡æ–°éƒ¨ç½²å‰ç«¯

---

### æ­¥éª¤ 3ï¼šéªŒè¯éƒ¨ç½²

1. è®¿é—®å‰ç«¯ URLï¼ˆVercel æä¾›çš„åœ°å€ï¼‰
2. ä¸Šä¼ æµ‹è¯•æ–‡ä»¶
3. éªŒè¯è¯„ä¼°åŠŸèƒ½æ­£å¸¸

---

## ðŸ³ æ–¹æ¡ˆäºŒï¼šDocker + äº‘æœåŠ¡å™¨

é€‚åˆéœ€è¦å®Œå…¨æŽ§åˆ¶çš„åœºæ™¯ï¼Œå¦‚ä¼ä¸šå†…ç½‘éƒ¨ç½²ã€‚

### æ­¥éª¤ 1ï¼šåˆ›å»º Dockerfile

#### åŽç«¯ Dockerfile
åœ¨ `backend/` ç›®å½•ä¸‹åˆ›å»º `Dockerfile`ï¼š

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶ä»£ç 
COPY . .

# å¤åˆ¶ scripts ç›®å½•ï¼ˆllm_evaluation_agent.py ä¾èµ–ï¼‰
COPY ../scripts /app/scripts

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### å‰ç«¯ Dockerfile
åœ¨ `frontend/` ç›®å½•ä¸‹åˆ›å»º `Dockerfile`ï¼š

```dockerfile
FROM node:20-alpine AS builder

WORKDIR /app

COPY package*.json ./
RUN npm ci

COPY . .

# æž„å»ºæ—¶éœ€è¦ API URL
ARG NEXT_PUBLIC_API_URL
ENV NEXT_PUBLIC_API_URL=$NEXT_PUBLIC_API_URL

RUN npm run build

# ç”Ÿäº§é•œåƒ
FROM node:20-alpine AS runner

WORKDIR /app

ENV NODE_ENV=production

COPY --from=builder /app/public ./public
COPY --from=builder /app/.next/standalone ./
COPY --from=builder /app/.next/static ./.next/static

EXPOSE 3000

CMD ["node", "server.js"]
```

> æ³¨æ„ï¼šéœ€è¦åœ¨ `frontend/next.config.ts` ä¸­æ·»åŠ  `output: 'standalone'`

### æ­¥éª¤ 2ï¼šåˆ›å»º Docker Compose

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `docker-compose.yml`ï¼š

```yaml
version: '3.8'

services:
  frontend:
    build:
      context: ./frontend
      args:
        NEXT_PUBLIC_API_URL: http://backend:8000
    ports:
      - "3000:3000"
    depends_on:
      - backend
    networks:
      - app-network

  backend:
    build:
      context: .
      dockerfile: ./backend/Dockerfile
    ports:
      - "8000:8000"
    environment:
      - LLM_API_KEY=${LLM_API_KEY}
      - LLM_BASE_URL=${LLM_BASE_URL}
      - LLM_MODEL=${LLM_MODEL}
    networks:
      - app-network

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - frontend
      - backend
    networks:
      - app-network

networks:
  app-network:
    driver: bridge
```

### æ­¥éª¤ 3ï¼šåˆ›å»º Nginx é…ç½®

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `nginx.conf`ï¼š

```nginx
events {
    worker_connections 1024;
}

http {
    upstream frontend {
        server frontend:3000;
    }

    upstream backend {
        server backend:8000;
    }

    server {
        listen 80;
        server_name your-domain.com;

        # å‰ç«¯
        location / {
            proxy_pass http://frontend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_cache_bypass $http_upgrade;
        }

        # åŽç«¯ API
        location /api/ {
            proxy_pass http://backend/api/;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
    }
}
```

### æ­¥éª¤ 4ï¼šéƒ¨ç½²åˆ°æœåŠ¡å™¨

```bash
# 1. å…‹éš†ä»£ç 
git clone https://github.com/Wu636/Agent_Evaluation.git
cd Agent_Evaluation

# 2. åˆ›å»ºçŽ¯å¢ƒå˜é‡æ–‡ä»¶
cat > .env << EOF
LLM_API_KEY=ä½ çš„APIå¯†é’¥
LLM_BASE_URL=http://llm-service.polymas.com/api/openai/v1/chat/completions
LLM_MODEL=gpt-4o
EOF

# 3. æž„å»ºå¹¶å¯åŠ¨
docker-compose up -d --build

# 4. æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f
```

---

## ðŸ“Š æ–¹æ¡ˆå¯¹æ¯”

| ç‰¹æ€§ | Vercel + Railway | Docker + äº‘æœåŠ¡å™¨ |
|------|------------------|-------------------|
| **éƒ¨ç½²éš¾åº¦** | â­ ç®€å• | â­â­â­ ä¸­ç­‰ |
| **æˆæœ¬** | å…è´¹èµ·æ­¥ | éœ€æœåŠ¡å™¨è´¹ç”¨ï¼ˆçº¦ Â¥50-200/æœˆï¼‰|
| **æ‰©å±•æ€§** | è‡ªåŠ¨æ‰©å±• | éœ€æ‰‹åŠ¨é…ç½® |
| **æŽ§åˆ¶æƒ** | å—é™äºŽå¹³å° | å®Œå…¨æŽ§åˆ¶ |
| **CI/CD** | è‡ªåŠ¨ | éœ€é…ç½® |
| **é€‚ç”¨åœºæ™¯** | ä¸ªäºº/æµ‹è¯•/å°å›¢é˜Ÿ | ç”Ÿäº§/ä¼ä¸š/é«˜å®‰å…¨è¦æ±‚ |

---

## ðŸ”§ å¸¸è§é—®é¢˜

### Q: å‰ç«¯æ— æ³•è¿žæŽ¥åŽç«¯ï¼Ÿ
- æ£€æŸ¥ `NEXT_PUBLIC_API_URL` çŽ¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®
- ç¡®ä¿åŽç«¯å·²å¯åŠ¨å¹¶å¯è®¿é—®
- æ£€æŸ¥ CORS é…ç½®

### Q: Railway éƒ¨ç½²å¤±è´¥ï¼Ÿ
- ç¡®è®¤ Root Directory è®¾ç½®ä¸º `backend`
- æ£€æŸ¥ `requirements.txt` æ˜¯å¦å®Œæ•´
- æŸ¥çœ‹éƒ¨ç½²æ—¥å¿—å®šä½é”™è¯¯

### Q: Vercel æž„å»ºå¤±è´¥ï¼Ÿ
- ç¡®è®¤ Root Directory è®¾ç½®ä¸º `frontend`
- æ£€æŸ¥ `package.json` ä¸­çš„ä¾èµ–æ˜¯å¦æ­£ç¡®
- æŸ¥çœ‹æž„å»ºæ—¥å¿—

---

## ðŸ“ž æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
- [å¿«é€Ÿå¼€å§‹æŒ‡å—](./QUICK_START.md)
- [LLM è¯„æµ‹æŒ‡å—](./LLM_EVALUATION_GUIDE.md)
- é¡¹ç›®ä»“åº“ï¼šhttps://github.com/Wu636/Agent_Evaluation
